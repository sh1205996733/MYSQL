[toc]



# MYSQL笔记

## MYSQL架构设计

## InnoDB存储引擎的架构设计

## MYSQL索引

### 磁盘数据页的存储结构

**数据库最终所有的数据（包括我们建的各种表以及表里的数据）都是要存放在磁盘上的文件里的，然后在文件里存放的物理格式就是数据页。数据页的内部结构：**

**大量的数据页是按顺序一页一页存放的，然后两两相邻的数据页之间会采用双向链表的格式互相引用**，大致看起来如下图所示。

![image-20211116112543828](E:\shangyc\docs\MYSQL笔记.assets\image-20211116112543828.png)

其实一个数据页在磁盘文件里就是一段数据，可能是二进制或者别的特殊格式的数据，然后数据页里包含两个指针，一个指针指向自己上一个数据页的物理地址，一个指针指向自己下一个数据页的物理地址，大概可以认为类似下面这样。

DataPage: xx=xx, xx=xx, linked_list_pre_pointer=15367, linked_list_next_pointer=34126 ||

DataPage: xx=xx, xx=xx, linked_list_pre_pointer=23789, linked_list_next_pointer=46589 ||

DataPage: xx=xx, xx=xx, linked_list_pre_pointer=33198, linked_list_next_pointer=55681

然后每个数据页里，可以认为就是DataPage打头一直到 || 符号的一段磁盘里的连续的数据，你可以认为每一个数据页就是磁盘文件里这么一段连续的东西

然后每个数据页，都有一个指针指向自己上一个数据页在磁盘文件里的起始物理位置，比如linked_list_pre_pointer=15367，就是指向了上一个数据页在磁盘文件里的起始物理位置，那个15367可以认为就是在磁盘文件里的position或者offffset，同理，也有一个指针指向自己下一个数据页的物理位置。

然后**一个数据页内部会存储一行一行的数据，也就是平时我们在一个表里插入的一行一行的数据就会存储在数据页里，然后数据页里的每一行数据都会按照主键大小进行排序存储，同时每一行数据都有指针指向下一行数据的位置，组成单向链表**，如下图。

![image-20211116112942998](E:\shangyc\docs\MYSQL笔记.assets\image-20211116112942998.png)

### 如果没有索引，数据库是如何搜索数据的

数据页之间是组成双向链表的，然后数据页内部的数据行是组成单向链表的，而且数据行是根据主键从小到大排序的。然后每个数据页里都会有一个页目录，里面根据数据行的主键存放了一个目录，同时数据行是被分散存储到不同的槽位里去的，所以实际上每个数据页的目录里，就是这个页里每个主键跟所在槽位的映射关

系，如下图所示

![image-20211116115624072](E:\shangyc\docs\MYSQL笔记.assets\image-20211116115624072.png)

#### 根据主键查找过程

- 直接从第一个数据页开始遍历所有数据页，从第一个数据页开始，先把第一个数据页从磁盘上读取到内存buffffer pool的缓存页里来

- 然后到数据页的页目录里根据主键进行二分查找。通过二分查找在目录里迅速定位到主键对应的数据是在哪个槽位里，然后到那个槽位里去，遍历槽

  位里每一行数据，就能快速找到那个主键对应的数据了。每个槽位里都有一组数据行，在里面遍历查找

- 查找不到，那只能根据双向链表继续加载下一个数据页到缓存页里来了，以此类推，循环往复

#### 非主键字段查找数据过程

原理同上，只是无法使用主键的那种页目录来二分查找的，只能进入到数据页里，根据单向链表依次遍历查找数据，查找不到，那只能根据双向链表继续加载下一个数据页到缓存页里来

![image-20211116135325361](E:\shangyc\docs\MYSQL笔记.assets\image-20211116135325361.png)

#### 全表扫描

上述操作过程，就是全表扫描，在你没有任何索引数据结构的时候，无论如何查找数据，说白了都是一个全表扫描的过程，就是根据双向链表依次把磁盘上的数据页加载到缓存页里去，然后在一个缓存页内部来查找那条数据。最坏的情况下，你就得把所有数据页里的每条数据都得遍历一遍，才能找到你需要的那条数据，这就是全表扫描

### 不断插入数据时，物理存储是如何进行页分裂的

也就是说，这个表里是如何出现一个又一个的数据页的。

正常情况下我们在一个表里插入一些数据后，他们都会进入到一个数据页里去，在数据页内部，他们会组成一个单向链表，这个数据页内部的单向链表大致如下所示：

![image-20211116135719009](E:\shangyc\docs\MYSQL笔记.assets\image-20211116135719009.png)

里面就是一行一行的数据，刚开始第一行是个起始行，他的行类型是2，就是最小的一行，然后他有一个指针指向了下一行数据，每一行数据都有自己每个字段的值，然后每一行通过一个指针不停的指向下一行数据，普通的数据行的类型都是0，最后一行是一个类型为3的，就是代表最大的一行

#### 页分裂

假设你不停的在表里插入数据，那么刚开始是不是就是不停的在一个数据页插入数据？接着数据越来越多，越来越多，此时就要再搞一个数据页了。但是此时会遇到一个问题，后续我们会讲到索引这块机制，索引运作的一个核心基础就是要求你后一个数据页的主键值都大于前面一个数据页的主键值，但是如果你的主键是自增的，那还可以保证这一点，因为你新插入后一个数据页的主键值一定都大于前一个数据页的主键值。但是有时候你的主键并不是自增长的，所以可能会出现你后一个数据页的主键值里，有的主键是小于前一个数据页的主键值的，此时就会出现一个过程，叫做**页分裂**

如果主键值都是你自己设置的，那么在增加一个新的数据页的时候，实际上会把前一个数据页里主键值较大的，挪动到新的数据页里来，然后把新插入的主键值较小的数据挪动到上一个数据页里去，保证新数据页里的主键值一定都比上一个数据页里的主键值大。这个过程叫做**页分裂**。如下图

![image-20211116140559198](E:\shangyc\docs\MYSQL笔记.assets\image-20211116140559198.png)

如上图所示，第一个数据页里有1、5、6三条数据，第二个数据页里有2、3、4三条数据，明显第二个数据页里的数据的主键值比第一个数据页里的5和6两个主键都小，所以这个是不行的。此时就会出现页分裂的行为，把新数据页里的两条数据挪动到上一个数据页，上一个数据页里挪两条数据到新数据页里去，如下图所示。

![image-20211116140841847](E:\shangyc\docs\MYSQL笔记.assets\image-20211116140841847.png)

所以上述就是一个页分裂的过程，核心目标就是保证下一个数据页里的主键值都比上一个数据页里的主键值要大。

### 索引检索原理

#### 主键索引

针对主键的索引实际上就是主键目录，这个主键目录就是把**每个数据页的页号，还有数据页里最小的主键值放在一起，组成一个索引的目录**，如下图所示

![image-20211116141505085](E:\shangyc\docs\MYSQL笔记.assets\image-20211116141505085.png)

直接就可以到主键目录里去搜索，比如你要找id=3的数据，此时就会跟每个数据页的最小主键来比，首先id=3大于了数据页2里的最小主键值1，接着小于了数据页8里的最小主键值4。所以既然如此，你直接就可以定位到id=3的数据一定是在数据页2里的！

如果有很多的数据页，在主键目录里就会有很多的数据页和最小主键值，此时完全可以根据二分查找的方式来确定目标id到底在哪个数据页里！这个效率是非常之高的，而类似上图的主键目录，就可以认为是主键索引

而大家都知道我们的数据页都是一坨一坨的连续数据放在很多磁盘文件里的，所以只要你能够根据主键索引定位到数据所在的数据页，此时假设我们有别的方式存储了数据页跟磁盘文件的对应关系，此时你就可以找到一个磁盘文件。而且我们假设数据页在磁盘文件里的位置也就是offffset偏移量，你也是可以知道的，此时就可以直接通过随机读的方式定位到磁盘文件的某个offffset偏移量的位置，然后就可以读取连续的 一大坨数据页了！

### 索引的页存储物理结构，是如何用B+树来实现的

主键目录的工作原理已了解，但是现在问题来了，你的表里的数据可能很多很多，比如有几百万，几千万，甚至单表几亿条数据都是有可能的，所以此时你可能有大量的数据页，然后你的主键目录里就要存储大量的数据页和最小主键值，这怎么行呢

实际上是采取了一种把索引数据存储在数据页里的方式来做的。也就是说，你的表的实际数据是存放在数据页里的，然后你表的索引其实也是存放在页里的，此时索引放在页里之后，就会有索引页，假设你有很多很多的数据页，那么此时你就可以有很多的索引页，此时如下图所示。

![image-20211116143333600](E:\shangyc\docs\MYSQL笔记.assets\image-20211116143333600.png)

但是现在又会存在一个问题了，你现在有很多索引页，但是此时你需要知道，你应该到哪个索引页里去找你的主键数据，是索引页20？还是索引页28？

于是接下来我们又可以把索引页多加一个层级出来，在更高的索引层级里，保存了每个索引页和索引页里的最小主键值，如下图所示。

![image-20211116143424618](E:\shangyc\docs\MYSQL笔记.assets\image-20211116143424618.png)

现在就好了，假设我们要查找id=46的，直接先到最顶层的索引页35里去找，直接通过二分查找可以定位到下一步应该到索引页20里去找，接下来到索引页20里通过二分查找定位，也很快可以定位到数据应该在数据页8里，再进入数据页8里，就可以找到id=46的那行数据了。

那么现在问题再次来了，假如你最顶层的那个索引页里存放的下层索引页的页号也太多了，怎么办呢？此时可以再次分裂，再加一层索引页，比如下面图里那样子，大家看看下图。

![image-20211116143713802](E:\shangyc\docs\MYSQL笔记.assets\image-20211116143713802.png)

**这就是一颗B+树**，属于数据结构里的一种树形数据结构，所以一直说MySQL的索引是用B+树来组成的，其实就是这个意思。

我们就以最简单最基础的主键索引来举例，当你为一个表的主键建立起来索引之后，其实这个主键的索引就是一颗B+树，然后当你要根据主键来查数据的时候，直接就是从B+树的顶层开始二分查找，一层一层往下定位，最终一直定位到一个数据页里，在数据页内部的目录里二分查找，找到那条数据。

这就是索引最真实的物理存储结构，采用跟数据页一样的页结构来存储，一个索引就是很多页组成的一颗B+树。

#### 基于索引数据结构去查找主键的过程

首先呢，现在假设我们要搜索一个主键id对应的行，此时你就应该先去顶层的索引页88里去找，通过二分查找的方式，很容易就定位到你应该去下层哪个索引页里继续找，如下图所示。

![image-20211116145012771](E:\shangyc\docs\MYSQL笔记.assets\image-20211116145012771.png)

比如现在定位到了下层的索引页35里去继续找，此时在索引页35里也有一些索引条目的，分别都是下层各个索引页（20，28，59）和他们里面最小的主键值，此时在索引页35的索引条目里继续二分查找，很容易就定位到，应该再到下层的哪个索引页里去继续找，如下图所示。

![image-20211116145025963](E:\shangyc\docs\MYSQL笔记.assets\image-20211116145025963.png)

我们这里看到，可能从索引页35接着就找到下层的索引页59里去了，此时索引页59里肯定也是有索引条目的，这里就存放了部分数据页页号（比如数据页2和数据页8）和每个数据页里最小的主键值。此时就在这里继续二分查找，就可以定位到应该到哪个数据页里去找，如下图所示

![image-20211116145108955](E:\shangyc\docs\MYSQL笔记.assets\image-20211116145108955.png)

接着比如进入了数据页2，里面就有一个页目录，都存放了各行数据的主键值和行的实际物理位置此时在这里直接二分查找，就可以快速定位到你要搜索的主键值对应行的物理位置，然后直接在数据页2里找到那条数据即可了。

其实最下层的索引页，都是会有指针引用数据页的，所以实际上索引页之间跟数据页之间是有指针连接起来的，如下图

![image-20211116145242358](E:\shangyc\docs\MYSQL笔记.assets\image-20211116145242358.png)

另外呢，其实索引页自己内部，对于一个层级内的索引页，互相之间都是基于指针组成双向链表的，如下面图示

![image-20211116145402318](E:\shangyc\docs\MYSQL笔记.assets\image-20211116145402318.png)

#### 聚簇索引

假设你把索引页和数据页综合起来看，他们都是连接在一起的，看起来就如同一颗完整的大的B+树一样，从根索引页88开始，一直到所有的

数据页，其实组成了一颗巨大的B+树。

在这颗B+树里，最底层的一层就是数据页，数据页也就是B+树里的叶子节点了！

所以，如果一颗大的B+树索引数据结构里，叶子节点就是数据页自己本身，那么此时我们就可以称这颗B+树索引为聚簇索引！也就是说，上图中所有的索引页+数据页组成的B+树就是聚簇索引！

#### InnoDB增删改原理

其实在InnoDB存储引擎里，你在对数据增删改的时候，就是直接把你的数据页放在聚簇索引里的，数据就在聚簇索引里，聚簇索引就包含了数据！比如你插入数据，那么就是在数据页里插入数据。如果你的数据页开始进行页分裂了，他此时会调整各个数据页内部的行数据，保证数据页内的主键值都是有顺序的，下一个数据页的所有主键值大于上一个数据页的所有主键值。同时会维护你的上层索引数据结构，在上层索引页里维护你的索引条目，不同的数据页和最小主键值。然后如果你的数据页越来越多，一个索引页放不下了，此时就会再拉出新的索引页，同时再搞一个上层的索引页，上层索引页里存放的索引条目就是下层索引页页号和最下主键值。

一般索引页里可以放很多索引条目，所以通常而言，即使你是亿级的大表，基本上大表里建的索引的层级也就三四层而已。

聚簇索引默认是按照主键来组织的，所以你在增删改数据的时候，一方面会更新数据页，一方面其实会给你自动维护B+树结构的聚簇索引，给新增和更新索引页，这个聚簇索引是默认就会给你建立的

### 二级索引运行原理

普通字段的索引称之为二级索引，一级索引就是聚簇索引。

针对其他字段建立索引，比如name、age之类的字段，这都是一样的原理，简单来说，比如你插入数据的时候，一方面会把完整数据插入到聚簇索引的叶子节点的数据页里去，同时维护好聚簇索引，另一方面会为你其他字段建立的索引，重新再建立一颗B+树。B+树的叶子节点也是数据页，但是这个数据页里仅仅放主键字段和name字段

![image-20211116152118555](E:\shangyc\docs\MYSQL笔记.assets\image-20211116152118555.png)

也就是说，name字段的索引B+树里，叶子节点的数据页中的name值都是按大小排序的，同时下一个数据页里的name字段值都大于上一个数据页里的name字段值，这个整体的排序规则都跟聚簇索引按照主键的排序规则是一样的。然后呢，name字段的索引B+树也会构建多层级的索引页，这个**索引页里存放的就是下一层的页号和最小name字段值**，整体规则都是一样的，只不过存放的都是name字段的值，根据name字段值排序罢了，看下图。

![image-20211116152349100](E:\shangyc\docs\MYSQL笔记.assets\image-20211116152349100.png)

补充一点，你的name字段的索引B+树里的索引页中，其实除了存放页号和最小name字段值以外，每个索引页里还会存放那个最小name字段值对应的主键值。

这是因为有时候会出现多个索引页指向的下层页号的最小name字段值是一样的，此时就必须根据主键判断一下。新的name字段值肯定是插入到主键值较大的那个数据页里去的

#### 回表

所以假设你要根据name字段来搜索数据，那搜索过程简直都一样了，不就是从name字段的索引B+树里的根节点开始找，一层一层往下找，一直找到叶子节点的数据页里，定位到name字段值对应的主键值。然后呢？此时针对select * from table where name='xx'这样的语句，你先根据name字段值在name字段的索引B+树里找，找到叶子节点也仅仅可以找到对应的主键值，而找不到这行数据完整的所有字段。所以此时还需要进行“**回表**”。

这个回表，就是说还需要根据主键值，再到聚簇索引里从根节点开始，一路找到叶子节点的数据页，定位到主键对应的完整数据行，此时才能把select *要的全部字段值都拿出来。

### 联合索引运行原理

多个字段联合起来，建立联合索引。联合索引运行原理和二级索引是一样的，只不过是建立一颗独立的B+树，叶子节点的数据页里放了id+name+age，然后默认按照name排序，name一样就按照age排序，不同数据页之间的name+age值的排序也如此。然后这个name+age的联合索引的B+树的索引页里，放的就是下层节点的页号和最小的name+age的值，以此类推，所以当你根据name+age搜索的时候，就会走name+age联合索引的这颗B+树了，搜索到主键，再根据主键**回表**到聚簇索引里去搜索。

### 插入数据时如何维护好不同索引的B+树的

首先呢，其实刚开始你一个表搞出来以后，其实他就一个数据页，这个数据页就是属于聚簇索引的一部分，而且目前还是空的此时如果你插入数据，就是直接在这个数据页里插入就可以了，也没必要给他弄什么索引页，如下图。

![image-20211116154138393](E:\shangyc\docs\MYSQL笔记.assets\image-20211116154138393.png)

然后呢，这个初始的数据页其实就是一个根页，每个数据页内部默认就有一个基于主键的页目录，所以此时你根据主键来搜索都是ok没有问题的，直接在唯一 一个数据页里根据页目录找就行了。然后你表里的数据越来越多了，此时你的数据页满了，那么就会搞一个新的数据页，然后把你根页面里的数据都拷贝过去，同时再搞一个新的数据页，根据你的主键值的大小进行挪动，让两个新的数据页根据主键值排序，第二个数据页的主键值都大于第一个数据页的主键值，如下图。

![image-20211116154338549](E:\shangyc\docs\MYSQL笔记.assets\image-20211116154338549.png)

此时根页就升级为索引页了，这个根页里放的是两个数据页的页号和他们里面最小的主键值，所以此时看起来如下图，根页就成为了索引页，引用了两个数据页。

![image-20211116154420869](E:\shangyc\docs\MYSQL笔记.assets\image-20211116154420869.png)

接着你肯定会不停的在表里灌入数据，然后数据页不停的页分裂，分裂出来越来越多的数据页此时你的唯一 一个索引页，也就是根页里存放的数据页索引条目越来越多，连你的索引页都放不下了，那你就让一个索引页分裂成两个索引页，然后根页继续往上走一个层级引用了两个索引页（分裂过程和数据页一样，跟索引页46引用28和59，原46索引页的数据会在索引页28中，新的数据会在索引页59中）

![image-20211116154801513](E:\shangyc\docs\MYSQL笔记.assets\image-20211116154801513.png)

接着就是依次类推了，你的数据页越来越多，那么根页指向的索引页也会不停分裂，分裂出更多的索引页，当你下层的索引页数量太多的时候，会导致你的根页指向的索引页太多了，此时根页继续分裂成多个索引页，根页再次往上提上去去一个层级。

这其实就是你增删改的时候，整个聚簇索引维护的一个过程，其实其他的二级索引也是类似的一个原理。

比如你name字段有一个索引，那么刚开始的时候你插入数据，一方面在聚簇索引的唯一的数据页里插入，一方面在name字段的索引B+树唯一的数据页里插入。

### 在MYSQL的表里建立字段对应的索引优缺点

优点：可以直接根据某个字段的索引B+树来查找数据，不需要全表搜索，性能提升是很高的。

缺点：

- 空间上而言，你要是给很多字段创建很多的索引，那你必须会有很多棵索引B+树，每一棵B+树都要占用很多的磁盘空间啊！所以你要是搞的索引太多了，是很耗费磁盘空间的
- 进行增删改查的时候，每次都需要维护各个索引的数据有序性，因为每个索引B+树都要求页内是按照值大小排序的，页之间也是有序的，下一个页的所有值必须大于上一个页的所有值！所以你不停的增删改查，必然会导致各个数据页之间的值大小可能会没有顺序，比如下一个数据页里插入了一个比较小的值，居然比上一个数据页的值要小！此时就没办法了，只能进行数据页的挪动，维护页之间的顺序。或者是你不停的插入数据，各个索引的数据页就要不停的分裂，不停的增加新的索引页，这个过程都是耗费时间的。

一个表里搞的索引太多了，很可能就会导致你的增删改的速度就比较差了，也许查询速度确实是可以提高，但是增删改就会受到影响，因此通常来说，我们是不建议一个表里搞的索引太多的！

### 深入理解联合索引查询原理以及全值匹配规则

前提条件

学生成绩表：包含了id（主键自增）、学生班级、学生姓名、科目名称、成绩分数四个字段，默认就会基于id做一个聚簇索引。针对学生班级、学生姓名和科目名称建立一个联合索引

数据准备

![image-20211116162822900](E:\shangyc\docs\MYSQL笔记.assets\image-20211116162822900.png)

#### 等值匹配规则

```sql
select * from student_score where class_name='1班' and student_name='张小强' and subject_name='数学'。
```

where条件里的几个字段都是基于等值来查询，都是用的等于号！而且where条件里的几个字段的名称和顺序也跟你的联合索引一模一样！此时就是等值匹配规则，上面的SQL语句是百分百可以用联合索引来查询的。，即使你where语句里写的字段的顺序和联合索引里的字段顺序不一致，也没关系，MySQL会自动优化为按联合索引的字段顺序去找。

联合索引的等值匹配规则查找过程

- 首先到索引页里去找，索引页里有多个数据页的最小值记录，此时直接在索引页里基于二分查找法来找就可以了，先是根据班级名称来找1班这个值对应的数据页，直接可以定位到他所在的数据页，
- 然后你就直接找到索引指向的那个数据页就可以了，在数据页内部本身也是一个单向链表，你也是直接就做二分查找就可以了，先按1班这个值来找，你会发现几条数据都是1班，此时就可以按照张小强这个姓名来二分查找，此时会发现多条数据都是张小强，接着就按照科目名称数学来二分查找。很快就可以定位到下图中的一条数据，1班的张小强的数学科目，他对应的数据的id是127
- 然后就根据主键id=127到聚簇索引里按照一样的思路，从索引根节点开始二分查找迅速定位下个层级的页，再不停的找，很快就可以找到id=127的那条数据，然后从里面提取所有字段

#### 最左侧列匹配

联合索引是KEY(class_name,student_name, subject_name)，则不一定必须要在where语句里根据三个字段来查，只要根据最左侧的部分字段来查，也可以的。但是假设你写一个select * from student_score where subject_name=''，那就不行了，因为联合索引的B+树里，是必须先按class_name查，再按student_name查，不能跳过前面两个字段，直接按最后一个subject_name查的。

另外，假设你写一个select * from student_score where class_name='' and subject_name=''，那么只有class_name的值可以在索引里搜索，剩下的subject_name是没法在索引里找的，道理同上。

#### 最左前缀匹配原则

如果你要用like语法来查，比如select * from student_scorewhere class_name like '1%'，查找所有1打头的班级的分数，那么也是可以用到索引的。因为你的联合索引的B+树里，都是按照class_name排序的，所以你要是给出class_name的确定的最左前缀就是1，然后后面的给一个模糊匹配符号，那也是可以基于索引来查找的，这是没问题的。

但是你如果写class_name like '%班'，在左侧用一个模糊匹配符，那他就没法用索引了，因为不知道你最左前缀是什么，怎么去索引里找啊

#### 范围查找规则

这个意思就是说，我们可以用select * from student_score whereclass_name>'1班' and class_name<'5班'这样的语句来范围查找某几个班级的分数。这个时候也是会用到索引的，因为我们的索引的最下层的数据页都是按顺序组成双向链表的，所以完全可以先找到'1班'对应的数据页，再找到'5班'对应的数据页，两个数据页中间的那些数据页，就全都是在你范围内的数据了

但是如果你要是写select * from student_score where class_name>'1班' and class_name<'5班' andstudent_name>''，这里只有class_name是可以基于索引来找的，student_name的范围查询是没法用到索引的

这也是一条规则，就是你的where语句里如果有范围查询，那只有对联合索引里最左侧的列进行范围查询才能用到索引！

#### 等值匹配+范围匹配的规则

如果你要是用select * from student_score whereclass_name='1班' and student_name>'' and subject_name<''，那么此时你首先可以用class_name在索引里精准定位到一波数据，接着这波数据里的student_name都是按照顺序排列的，所以student_name>''也会基于索引来查找，但是接下来的subject_name<''是不能用索引的。

### SQL排序的时候，如何才能使用索引

select * from table where xxx=xxx order by xxx这样的一个SQL语句，似乎应该是基于where语句通过索引快速筛选出来一波数据，接着放到内存里，或者放在一个临时磁盘文件里，然后通过排序算法按照某个字段走一个排序，最后把排序好的数据返回。但是这么搞通常速度有点慢，尤其是万一你要排序的数据量比较大的话，还不能用内存来排序，如果基于磁盘文件来排序，那在MySQL里有一个术语，叫做fifilesort，这速度就比较慢了。

尤其是类似于select * from table order by xx1,xx2,xx3 limit100这样的SQL语句，先排序在分页，简直速度很慢

所以通常而言，在这种情况下，假设我们建立了一个INDEX(xx1,xx2,xx3)这样的一个联合索引，这个时候默认情况下在索引树里本身就是依次按照xx1,xx2,xx3三个字段的值去排序的，那么此时你再运行select * from table order by xx1,xx2,xx3 limit 100这样的SQL语句就会直接在索引中排好顺序，直接limit100条数据的主键再去聚簇索引里回表查询剩余所有的字段

但是这里有一些限定规则，因为联合索引里的字段值在索引树里都是从小到大依次排列的 ，所以你在order by里要不然就是每个字段后面什么都不加，直接就是order by xx1,xx2,xx3，要不然就都加DESC降序排列，就是order by xx1 DESC,xx2 DESC,xx3 DESC。

如果都是升序排列，直接就从索引树里最小的开始读取一定条数就可以了，要是都是降序排列，就是从索引树里最大的数据开始读取一定的条数就可以了，但是你不能order by语句里有的字段升序有的字段降序，那是不能用索引的。

另外，要是你order by语句里有的字段不在联合索引里，或者是你对order by语句里的字段用了复杂的函数，这些也不能使用索引去进行排序了。

#### SQL分组的时候，如何才能使用索引

那假设你要是走一个类似select count(*) from table group by xx的SQL语句，似乎看起来必须把你所有的数据放到一个临时磁盘文件里还有加上部分内存，去搞一个分组，按照指定字段的值分成一组一组的，接着对每一组都执行一个聚合函数，这个性能也是极差的，因为毕竟涉及大量的磁盘交互。

因为在我们的索引树里默认都是按照指定的一些字段都排序好的，其实字段值相同的数据都是在一起的，假设要是走索引去执行分组后再聚合，那性能一定是比临时磁盘文件去执行好多了。所以通常而言，对于group by后的字段，最好也是按照联合索引里的最左侧的字段开始，按顺序排列开来，这样的话，其实就可以完美的运用上索引来直接提取一组一组的数据，然后针对每一组的数据执行聚合函数就可以了。

表设计两三个常用的索引，覆盖常见的where筛选、order by排序和group by分组的需求，保证常见的SQL语句都可以用上索引，这样你真正系统跑起来，起码是不会有太大的查询性能问题了。

### 回表查询对性能的损害

类似select * from table order by xx1,xx2,xx3的语句，可能你就是得从联合索引的索引树里按照顺序取出来所有数据，接着对每一条数据都走一个主键的聚簇索引的查找，其实性能也是不高的。

有的时候MySQL的执行引擎甚至可能会认为，你要是类似select * from table order by xx1,xx2,xx3的语句，相当于是得把联合索引和聚簇索引，两个索引的所有数据都扫描一遍了，那还不如就不走联合索引了，直接全表扫描得了，这样还就扫描一个索引而已。

但是你如果要是select * from table order by xx1,xx2,xx3 limit 10这样的语句，那执行引擎就知道了，你先扫描联合索引的索引树拿到10条数据，接着对10条数据在聚簇索引里查找10次就可以了，那么就还是会走联合索引的。

### 覆盖索引

覆盖索引不是一种索引，而是一种基于索引查询的方式。需要的字段值直接在索引树里就能提取出来，不需要回表到聚簇索引，这种查询方式就是覆盖索引

意思就是针对类似select xx1,xx2,xx3 from table order by xx1,xx2,xx3这样的 语句，这种情况下，你仅仅需要联合索引里的几个字段的值，那么其实就只要扫描联合索引的索引树就可以了，不需要回表去聚簇索引里找其他字段了

也正是这样，所以在写SQL语句的时候，一方面是你要注意一下也许你会用到联合索引，但是是否可能会导致大量的回表到聚簇索引，如果需要回表到聚簇索引的次数太多了，可能就直接给你做成全表扫描不走联合索引了；一方面是尽可能还是在SQL里指定你仅仅需要的几个字段，不要搞一个select *把所有字段都拿出来，甚至最好是直接走覆盖索引的方式，不要去回表到聚簇索引。

即使真的要回表到聚簇索引，那你也尽可能用limit、where之类的语句限定一下回表到聚簇索引的次数，就从联合索引里筛选少数数据，然后再回表到聚簇索引里去，这样性能也会好一些。

### 前缀索引

类似 my_index(name(20),age,course)这种。这个字段里的每个值的前20个字符放在索引树里

对于那种比较长的字符串类型的列，可以设计前缀索引，仅仅包含部分字符到索引树里去，where查询还是可以用的 ，根据name字段来搜索，那么此时就会先到索引树里根据name字段的前20个字符去搜索，定位到之后前20个字符的前缀匹配的部分数据之后，再回到聚簇索引提取出来完整的name字段值进行比对。

但是order by和group by就用不上了，因为在索引树里仅仅包含了前20个字符，所以这个排序是没法用上索引了

### 函数索引

8.0之后新加的特性。

```mysql
alter  table tb_function add key idx_create_time((date(create_time))); --   注意里面字段的括号
```

### 索引设计原则

- 针对SQL语句中的where条件、order by条件以及group by条件去设计一个或者两三个联合索引

  每一个联合索引都尽量去包含上你的where、order by、group by里的字段，并且每个where、order by、group by后面跟的字段顺序，都是某个联合索引的最左侧字段开始的部分字段

- **一般建立索引，尽量使用那些基数比较大的字段，就是值比较多的字段，那么才能发挥出****B+树快速二分查找的优势来。**其次的话，你尽量是对那些**字段的类型比较小的列来设计索引**，比如说什么tinyint之类的，因为这个字段的值占用磁盘空间小，此时你在搜索的时候性能也会比较好一点。varchar(255)的字段这种的字段，可以针对前20个字符建立索引。类似 my_index(name(20),age,course)这种

- 不要再索引列套函数，8.0之后可以使用函数索引

因为你插入的数据值可能根本不是按照顺序来的，很可能会导致索引树里的某个页就会自动分裂，这个页分裂的过程就很耗费时间，**因此一般让大家设计索引别太多，建议两三个联合索引就应该覆盖掉你这个表的全部查询了**

**另外很关键一点，建议大家主键一定是自增的，别用****UUID****之类的**，因为主键自增，那么起码你的聚簇索引不会频繁的分裂，主键值都是有序的，就会自然的新增一个页而已，但是如果你用的是UUID，那么也会导致聚簇索引频繁的页分裂。

## MYSQL执行计划

每次提交的SQL给MySQL，他内核里的查询优化器，都会针对这个SQL语句的语义去生成一个执行计划，这个执行计划就代表了，他会怎么查各个表，用哪些索引，如何做排序和分组，这个过程就叫**执行计划！**

### 执行计划内容

- const ：通过主键或者唯一索引的访问，速度超高。执行计划里看到const的时候，就知道他就是直接通过索引定位到数据，速度极快，这就是const的意思。但是这里有一个要点，你的二级索引必须是唯一索引，才是属于const方式的，也就是说你必须建立unique key唯一索引，保证一个二级索引的每一个值都是唯一的，才可以
- ref：就是用了普通的索引，或者用主键/唯一索引搞了一个IS NULL/ISNOT NULL。如果你是包含多个列的普通索引的话，那么必须是从索引最左侧开始连续多个列都是等值比较才可以是属于ref方式，就是类似于select * from table where name=x and age=x and xx=xx，然后索引可能是个KEY(name,age,xx)。
- ref_or_null：就是如果你用name IS NULL这种语法的话，即使name是主键或者唯一索引，还是只能走ref方式。但是如果你是针对一个二级索引同时比较了一个值还有限定了IS NULL，类似于select *from table where name=x and name IS NULL
- range：利用索引做了范围筛选，那么这种方式就是range
- index：会直接遍历KEY(x1,x2,x3)索引树的叶子节点的那些页，一个接一个的遍历，然后找到 x2=xxx 的那个数据，就把里面的x1，x2，x3三个字段的值直接提取出来就可以了！这个遍历二级索引的过程，要比遍历聚簇索引快多了，毕竟二级索引叶子节点就包含几个字段的值，比聚簇索引叶子节点小多了，所以速度也快！针对那种只要遍历二级索引树的叶子节点的方式就可以拿到你想要的数据，而不需要回源到聚簇索引的访问方式，就叫做index访问方式

### 写SQL语句的时候，会用什么执行计划？

之前我们都是说，一般一个SQL语句只能用到一个二级索引，但是有一些特殊的情况下，可能会对一个SQL语句用到多个二级索引，这是怎么回事呢？

比如有这么一个SQL：select * from table where x1=xx and x2=xx，然后x1和x2两个字段分别都有一个索引，其实也有一定的可能会让查询优化器生成一个执行计划，执行计划里，就先对x1字段的索引树进行查找，查出一波数据，接着对x2的索引树查出一波数据，然后对两波数据，按照主键值做一个交集。这个交集就是符合两个条件的数据了，接着回表到聚簇索引去查完整数据就可以了。

但是如果要在一个SQL里用多个索引，那有很多硬性条件的要求，比如说如果有联合索引，你必须把联合索引里每个字段都放SQL里，而且必须都是等值匹配；或者是通过主键查询+其他二级索引等值匹配，也有可能会做一个多索引查询和交集。

其实如果你在SQL里写了类似x1=xxor x2=xx的语句，也可能会用多个索引，只不过查多个大索引树之后，会取一个并集，而不是交集罢了

### MYSQL的多表关联查询SQL语句是如何执行的

```mysql
select * from t1,t2 where t1.x1=xxx and t1.x2=t2.x2 and t2.x3=xxx
```

可能是先从一个表里查一波数据，这个表叫做“驱动表”，再根据这波数据去另外一个表里查一波数据进行关联，另外一个表叫做“被驱动表”.

这个SQL执行的过程可能是这样的，首先根据t1.x1=xxx这个筛选条件，去t1表里查出来一批数据，此时可能是const、ref，也可能是index或者all，都有可能。接着对筛选出来的数据，根据每条数据的x2字段的值，以及t2.x3=xxx这个条件，去t2表里找x2字段值和x3字段值都匹配的数据。

#### 内连接

inner join，意思就是要求两个表里的数据必须是完全能关联上的，才能返回回来，这就是内连接。默认就是内连接

#### 外连接

outer join。这个outer join分为左外连接(LEFT OUTER JOIN)和右外连接(RIGHT OUTER JOIN)，左外连接的意思就是，在左侧的表里的某条数据，如果在右侧的表里关联不到任何数据，也得把左侧表这个数据给返回出来，右外连接反之，在右侧的表里如果关联不到左侧表里的任何数据，得把右侧表的数据返回出来。

这里还有一个语法限制，如果你是之前的那种内连接，那么连接条件是可以放在where语句里的，但是外连接一般是把连接条件放在ON字句里的，

#### 全连接

MySQL本身不支持你所说的full join（全连接），但可以通过union来实现

[数据库——自然连接、内连接、外连接（左外连接、右外连接、全外连接）、交叉连接](https://blog.csdn.net/qq_38125058/article/details/79946850?spm=1001.2101.3001.6650.1&utm_medium=distribute.pc_relevant.none-task-blog-2%7Edefault%7ECTRLIST%7Edefault-1.no_search_link&depth_1-utm_source=distribute.pc_relevant.none-task-blog-2%7Edefault%7ECTRLIST%7Edefault-1.no_search_link)

**嵌套循环关联（nested-loop join）**

其实就是我们之前给大家提到的最基础的关联执行原理。多表表关联就是先从驱动表里根据WHERE条件去筛选一波数据之后，要对每一条数据都循环一次去被驱动表里查询数据。这种方法的伪代码有点类似下面这样

![image-20211119103145836](E:\shangyc\docs\MYSQL笔记.assets\image-20211119103145836.png)

所以万一你要是被驱动表的索引都没建好，总不能每次都全表扫描吧？这就是一个很大的问题！另外一个，刚开始对你的驱动表根据WHERE条件进行查询的时候，也总不能全表扫描吧？这也是一个问题！所以说，为什么有的时候多表关联很慢呢？答案就在这里了。

所以说，通常而言，针对多表查询的语句，我们要尽量给两个表都加上索引，索引要确保从驱动表里查询也是通过索引去查找，接着对被驱动表查询也通过索引去查找。如果能做到这一点，你的多表关联语句性能就会很高！

### MYSQL是如何根据成本优化选择执行计划的

#### IO成本

MySQL里的成本是什么意思，简单来说，跑一个SQL语句，一般成本是两块，首先是那些数据如果在磁盘里，你要不要从磁盘里把数据读出来？这个从磁盘读数据到内存就是IO成本，而且MySQL里都是一页一页读的，读一页的成本的约定为1.0。

#### CPU成本

还有一个成本，那就是说你拿到数据之后，是不是要对数据做一些运算？比如验证他是否符合搜索条件了，或者是搞一些排序分组之类的事，这些都是耗费CPU资源的，属于CPU成本，一般约定读取和检测一条数据是否符合条件的成本是0.2.

这个所谓1.0和0.2就是他自定义的一个成本值，代表的意思就是一个数据页IO成本就是1.0，一条数据检测的CPU成本就是0.2

#### 全表扫描的成本计算方法

使用命令：show table status like "表名"

可以拿到你的表的统计信息，你在对表进行增删改的时候，MySQL会给你维护这个表的一些统计信息，比如这里可以看到rows和data_length两个信息，不过对于innodb来说，这个rows是估计值。rows就是表里的记录数，data_length就是表的聚簇索引的字节数大小，此时用data_length除以1024就是kb为单位的大小，然后再除以16kb（默认一页的大小），就是有多少页，此时知道数据页的数量和rows记录数，就可以计算**全表扫描的成本**了。IO成本就是：数据页数量 * 1.0 + 微调值，CPU成本就是：行记录数 * 0.2 + 微调值，他们俩相加，就是一个总的成本值，比如你有数据页100个，记录数有2万条，此时总成本值大致就是100 + 4000 =

4100，在这个左右。

#### 索引的成本计算方法

除非你直接根据主键查，那就直接走一个聚簇索引就ok了，否则普通索引，一般都是两步走，先从二级索引查询一波数据，再根据这波数据的主键去聚簇索引回表查询。

- 首先，在二级索引里根据条件查一波数据的IO成本，一般是看你的查询条件涉及到几个范围，比如说name值在25~100，250~350两个区间，那么就是两个范围，否则name=xx就仅仅是一个范围区间。一般一个范围区间就粗暴的认为等同于一个数据页。IO成本都会预估的很小，可能就是1 * 1.0 = 1，或者是n * 1.0 = n，基本就是个位数这个级别
- 二级索引数据页到内存里以后，还得根据搜索条件去拿出来一波数据，拿这波数据的过程就是根据搜索条件在二级索引里搜索的过程。比如估算可能会查到100条数据，此时从二级索引里查询数据的CPU成本就是100 * 0.2+ 微调值，总之就是20左右而已。
- 接着你拿到100条数据之后，就得回表到聚簇索引里去查询完整数据，此时先估算回表到聚簇索引的IO成本，这里比较粗暴的直接默认1条数据就得回表到聚簇索引查询一个数据页，所以100条数据就是100个数据页的IO成本，也就是100 * 1.0 + 微调值，大致是100左右。
- 此时就可以针对这100条数据去判断，他们是否符合其他查询条件了，这里耗费的CPU成本就是100 * 0.2 + 微调值，就是20左右

把上面的所有成本都加起来，就是1 + 20 + 100 + 20 = 141，这就是使用一个索引进行查询的成本的计算方法。所以一般就会针对全表扫描和各个索引的成本，都进行估算，然后比较一下，选择一个成本最低的执行计划。

#### 多表关联查询是如何选择执行计划

```mysql
select * from t1 join t2 on t1.x1=t2.x1 where t1.x2=xxx and t1.x3=xxx and t2.x4=xxx and t2.x5=xxx
```

首先就会按照之前讲的那套方法来计算针对t1表查询的全表扫描和不同索引的成本，选择一个针对t1表的最佳访问方式，用最低成本从t1表里查出符合条件的数据来。

接着就根据这波数据得去t2表里查数据，按照连接条件t1.x1=t2.x1去查，同时要符合t2.x4=xxx和t2.x5=xxx这两个条件。此时一样会根据之前讲解的办法去估算，针对t2表的全表扫描以及基于x4、x5、x1几个字段不同索引的访问的成本，挑选一个成本最低的方法，然后从t2表里把数据给查找出来，就可以，这就完成了多表关联

### MYSQL是如何基于各种规则去优化执行计划的

#### 等值优化

首先呢，要是MySQL觉得你的SQL里有很多括号，那么无关紧要的括号他会给你删除了，其次比如你有类似于i = 5 and j > i这样的SQL，就会改写为i = 5 and j > 5，做一个常量替换。

还有比如x = y and y = k and k = 3这样的SQL，都会给你优化成x = 3 and y = 3 and k = 3，本质也是做个常量替换。或者是类似于什么b = b and a = a这种一看就是乱写的SQL，一看就是没意义的，就直接给你删了。

- 优化二

select * from t1 join t2 on t1.x1=t2.x1 and t1.id=1

这个SQL明显是针对t1表的id主键进行了查询，同时还要跟t2表进行关联，其实这个SQL语句就可能在执行前就先查询t1表的id=1的数据，然后直接做一个替换，把SQL替换为：select t1表中id=1的那行数据的各个字段的常量值, t2.* from t1 join t2 on t1表里x1字段的常量值=t2.x1上面的SQL就是直接把t1相关的字段都替换成了提前查出来的id=1那行数据的字段常量值了。

#### 子查询是如何执行以及优化

select * from t1 where x1 = (select x1 from t2 where id=xxx)上面的SQL语句在执行的时候，其实会被拆分为两个步骤：第一个步骤先执行子查询，也就

是：select x1 from t2 where id=xxx，直接根据主键定位出一条数据的x1字段的值。接着再执行select * from t1 where x1=子查询的结果值

另外还有一种子查询，就是：select * from t1 where x1 = (select x1 from t2 where t1.x2=t2.x2)

这种时候，你会发现子查询里的where条件依赖于t1表的字段值，所以这种查询就会效率很低下，他需要遍历t1表里每一条数据，对每一条数据取出x2字段的值，放到子查询里去执行，找出t2表的某条数据的x1字段的值，再放到外层去判断，是否符合跟t1表的x1字段匹配。

#### IN语句优化

select * from t1 where x1 in (select x2 from t2 where x3=xxx)

这个SQL先执行子查询，然后对t1表再进行全表扫描，判断每条数据是否在这个子查询的结果集里，但是这种方式其实效率是非常低下的。执行计划会被优化为。先执行子查询，也就是select x2 from t2 where x3=xxx这条SQL语句，把查出来的数据都写入一个临时表里，也可以叫做物化表，意思就是说，把这个

中间结果集进行物化。

这个物化表可能会基于memory存储引擎来通过内存存放，如果结果集太大，则可能采用普通的b+树聚簇索引的方式放在磁盘里。但是无论如何，这个物化表都会建立索引，所以大家要清楚，这波中间结果数据写入物化表是有索引的。

接着大家可能会想，此时是不是全表扫描t1表，对每条数据的x1值都去物化表里根据索引快速查找一下是否在这个物化表里？如果是的话，那么就符合条件了。但是这里还有一个优化的点，那就是他可以反过来思考。

也就是说，假设t1表的数据量是10万条，而物化表的数据量只有500条，那么此时完全可以改成全表扫描物化表，对每个数据值都到t1表里根据x1这个字段的索引进行查找，查找物化表的这个值是否在t1表 的x1索引树里，如果在的话，那么就符合条件了。

所以基于IN语句的子查询执行方式，实际上会在底层被优化成如上所述。

#### semi join半连接优化

对子查询的执行计划进行优化的一种方式，就是semi join，也就是半连接。

select * from t1 where x1 in (selectx2 from t2 where x3=xxx)，此时其实可能会在底层把他转化为一个半连接，有点类似于下面的样子：

select t1.* from t1 semi join t2 on t1.x1=t2.x2 and t2.x3=xxx当然，其实并没有提供semi join这种语法，这是MySQL内核里面使用的一种方式，上面就是给大家说那么个意思，其实上面的semi join的语义，是和IN语句+子查询的语义完全一样的，他的意思就是说，对于t1表而言，只要在t2表里有符合t1.x1=t2.x2和t2.x3=xxx两个条件的数据就可以了，就可以把t1表的数据筛选出来了。

当然，其实还是要给大家提醒一句，在互联网公司里，我们比较崇尚的是尽量写简单的SQL，复杂的逻辑用Java系统来实现就可以了，SQL能单表查询就不要多表关联，能多表关联就尽量别写子查询，能写几十行SQL就别写几百行的SQL，多考虑用Java代码在内存里实现一些数据就的复杂计算逻辑，而不是都放SQL里做。

### SQL执行计划

所谓的执行计划，落实到底层，无非就是先访问哪个表，用哪个索引还是全表扫描，拿到数据之后如何去聚簇索引回表，是否要基于临时磁盘文件做分组聚合或者排序，其实这个计划到最后就是这点东西。**另外不同的MySQL版本都可能会调整生成执行计划的方式，所以同样的SQL在不同的MySQL版本下跑 ，可能执行计划都不太一样。**

explain select * from table

```mysql
explain select * from table
id | select_type | table | partitions | type | possible_keys | key | key_len | ref | rows | filtered |
Extra 
|+----+-------------+-------+------------+------+---------------+------+---------+------+------+----------+----------------+| 
1 | SIMPLE | NULL | NULL | NULL | NULL | NULL | NULL | NULL | NULL | NULL | No
tables used |
```

id:select查询序列号，包含一组数字，表示查询中执行select子句或操作表的顺序。就是说每个SELECT都会对应一个唯一的id，一个复杂的SQL里可能会有很多个SELECT，也可能会包含多条执行计划，每一条执行计划都会有一个唯一的id，这个ID代表这执行顺序，id不同，id值越大优先级越高，越先被执行，id相同,执行顺序由上向下。id如果相同,可以认为是一组,从上往下执行,在所有组中id值越大,优先级越高,越先执行。

select_type：查询类型

table：查询使用的表名。（为null表示就是一个子查询结果集物化形成的临时表，他是直接针对这个物化临时表进行了全表扫描根据where条件进行筛选的）

partitions：是表分区的概念

type：访问方式。system > const（基于主键的等值常量查询） >eq_ref （基于主键进行等值匹配）> ref （基于二级索引进行等值匹配的时候/基于二级索引查询的时候允许值为nullref_or_null）> range(基于二级索引进行范围查询) > index(直接扫描二级索引的叶子节点) >all (扫描聚簇索引的叶子节点每条数据)之类的，分别代表了使用聚簇索引、二级索引、全表扫描之类的访问方式(index_merge针对单表查询可能会基于多个索引提取数据后进行合并)

possible_keys：基于type类型，可能会使用到的索引

key：在possible_keys里实际选择的那个索引

key_len：使用索引的长度(那个索引里的最大值的长度是多少，大概知道那个索引里的值最大能有多长，也可以看出联合索引是否都使用)

ref：就是使用某个字段的索引进行等值匹配搜索的时候，跟索引列进行等值匹配的那个目标值的一些信息。

​	当你的查询方式是索引等值匹配的时候，比如const、ref、eq_ref、ref_or_null这些方式的时候，此时执行计划的ref字段告诉你的就是：你跟索引列等值匹配的是什么？是等值匹配一个常量值？还是等值匹配另外一个字段的值？

rows:是预估通过索引或者别的方式访问这个表的时候，大概会查出来多少条数据

filtered:经过搜索条件过滤之后的剩余数据的百分比。在查询方式查出来的这波数据里再用上其他的不在索引范围里的查询条

件，又会过滤出来百分之几的数据。例如基于x1>'xxx'这个条件通过index_x1索引查询出来的数据大概是1987条，接着会针对这1987条数据再基于where条件里的其他条件，也就是x2='xxx'进行过滤。这个filtered是13.00，意思是估算基于x2='xxx'条件过滤后的数据大概是13%，也就是说最终查出来的数据大概是1987 * 13% = 258条左右。

extra:是一些额外的信息。很重要

- Using index： 如果没有回表操作，仅仅在二级索引里执行，那么extra里会告诉in是Using index

​		SELECT x1 FROM t1 WHERE x1 = 'xxx'

- Using index condition:在二级索引index_x1里查找，查找出来的结果还会额外的跟where 其他条件做比对，如果满足条件的才会被筛选出来

​		SELECT * FROM t1 WHERE x1 > 'xxx' AND x1 LIKE '%xxx'先在二级索引index_x1里查找，查找出来的结果还会额外的跟x1 LIKE '%xxx'条件做比对

- Using where:一般是见于你直接针对一个表扫描，没用到索引，然后where里好几个条件或者是用了索引去查找，但是除了索引之外，还需要用其他的

  字段进行筛选

   SELECT * FROM t1 WHERE x2 = 'xxx'这里的x2是没有建立索引的,针对t1表进行查询，用的是全表扫描方式，没有使用任何索引

  SELECT * FROM t1 WHERE x1 = 'xxx' AND x2 = 'xxx'针对t1表去查询，先通过ref方式直接在index_x1索引里查找，是跟const代表的常量值去查找.接着再用Using where代表的方式，去使用AND x2 = 'xxx'条件进行筛选，筛选后的数据比例是xx

  SELECT * FROM t1 INNER JOIN t2 ON t1.x2 = t2.x2多表关联有的关联条件并不是索引此时t1、t2都是全表扫描。根据extra提示的Using where，就是根据t1表每条数据的x2字段的值去t2表查找对应的数据，然后此时会用**join buffffer**技术，在内存里做一些特殊优化，减少t2表的全表扫描次数

- Using filesort：排序的时候是没法用到索引的，此时就会基于内存或者磁盘文件来排序，大部分时候得都基于磁盘文件来排序

  SELECT * FROM t1 ORDER BY x2 LIMIT 10 x2字段是没有索引的基于x2字段来排序，是没法直接根据有序的索引去找数据的，只能把所有数据写入一个临时的磁盘文件，基于排序算法在磁盘文件里按照x2字段的值完成排序，然后再按照LIMIT 10的要求取出来头10条数据。性能其实会极差的

- Using temprory：如果我们用group by、union、distinct之类的语法的时候，万一你要是没法直接利用索引来进行分组聚合，那么他会直接基于临时表来完成，也会有大量的磁盘操作，性能其实也是极低的

  SELECT x2, COUNT(*) AS amount FROM t1 GROUP BY x2这个SQL里只能对全表数据放到临时表里做大量的磁盘文件操作，然后才能完成对x2字段的不同的值去分组，分组完了以后对不同x2值的分组去做聚合操作，这个过程也是相当的耗时的，性能是极低的。

**所以大家最后记住，其实未来在SQL调优的时候，核心就是分析执行计划里哪些地方出现了全表扫描，或者扫描数据过大，尽可能通过合理优化索引保证执行计划每个步骤都可以基于索引执行，避免扫描过多的数据。**

## 生产经验：

### 真实生产环境下的数据库机器配置如何规划

#### 生产数据库一般用什么配置的机器

​		应用系统部署的时候常选用的机器配置大致是2核4G和4核8G的较多一些，数据库部署的时候常选用的机器配置最低在8核16G以上，正常在16核32G。那么以我们大量的高并发线上系统的生产经验观察下来而言，一般Java应用系统部署在4核8G的机器上，每秒钟抗下500左右的并发访问量，差不多是比较合适的，当然这个也不一定。假设每个请求花费1s可以处理完，那一台机器每秒也许只可以处理100个请求，但是如果每个请求只要花费100ms就可以处理完，那一台机器每秒也许就可以处理几百个请求。但是大体上来说，根据我们大量的经验观察而言，4核8G的机器部署普通的Java应用系统，每秒大致就是抗下几百的并发访问，从每秒一两百请求到每秒七八百请求，都是有可能的，关键是看你每个请求处理需要耗费多长时间。

#### 高并发场景下，数据库机器应该怎么选择

​	通常推荐的数据库至少是选用8核16G以的机器，甚至是16核32G的机器更加合适一些。因为对于我们的Java应用系统，主要耗费时间的是Java系统和数据库之间的网络通信。对Java系统而言，如果你仅仅只是系统内部运行一些普通的业务逻辑，纯粹在自己内存中完成一些业务逻辑，这个性能是极高极高的。所以Java系统其实主要的压力和复杂都是集中在你依赖的那个MySQL数据库上的！因为你执行大量的增删改查的SQL语句的时候，MySQL数据库需要对内存和磁盘文件进行大量的IO操作，所以数据库往往是负载最高的！

​	一般8核16G的机器部署的MySQL数据库，每秒抗个一两千并发请求是没问题的，但假设每秒有几千并发请求，那么可能数据库就会有点危险了，因为数据库的CPU、磁盘、IO、内存的负载都会很高，弄不数据库压力过大就会宕机。

​	对于16核32G的机器部署的MySQL数据库而言，每秒抗个两三千，甚至三四千的并发请求也都是可以的，但是如果你达到每秒上万请求，那么数据库的CPU、磁盘、IO、内存的负载瞬间都会飙升到很高，数据库也是可能会扛不住宕机的。

​	另外对于数据库而言，如果可以的话，最好是采用SSD固态硬盘而不是普通的机械硬盘，因为数据库最大的复杂就在于大量的磁盘IO，他需要大量的读写磁盘文件，所以如果能使用SSD固态硬盘，那么你的数据库每秒能抗的并发请求量就会更高一些

### 数据库的压测过程中，如何360度无死角观察机器性能

#### QPS和TPS到底有什么区别

- Query Per Second：QPS就是说这个数据库每秒可以处理多少个请求，大致可以理解为，一次请求就是一条SQL语句，也就是说这个数据库每秒可以处理多少个SQL语句，对于QPS而言，其实一些Java系统或者中间件系统在进行压测的时候，也可以使用这个指标，也就是说，这个Java系统每秒可以处理多少个请求

- Transaction Per Second：其实就是每秒可处理的事务量，这个TPS往往是用在数据库中较多一些，其实从字面意思就能看的出来，他就是说数据库每秒会处理多少次事务提交或者回滚。所以TPS往往指的是一个数据库每秒里有多少个事务执行完毕了，事务提交或者回滚都算是事务执行完毕了，所以TPS衡量的是一个数据库每秒处理完的事务的数量。有一些人往往会把TPS理解为是数据库每秒钟处理请求的数量，其实这是不太严谨的。

- **IO相关的压测性能指标**

  - **IOPS：**这个指的是机器的随机IO并发处理的能力，比如机器可以达到200 IOPS，意思就是说每秒可以执行200个随机IO读写请求。

    这个指标是很关键的，因为之前我们在数据库架构原理中讲解过，你在内存中更新的脏数据库，最后都会由后台IO线程在不确定的时间，刷回到磁盘里去，这就是随机IO的过程。如果说IOPS指标太低了，那么会导致你内存里的脏数据刷回磁盘的效率就会不高。

  - **吞吐量：**这个指的是机器的磁盘存储每秒可以读写多少字节的数据量

    这个指标也是很关键的，因为大家通过之前的学习都知道，我们平时在执行各种SQL语句的时候，提交事务的时候，其实都是大量的会写redo log之类的日志的，这些日志都会直接写磁盘文件。所以一台机器他的存储每秒可以读写多少字节的数据量，就决定了他每秒可以把多少redo log之类的日志写入到磁盘里去。一般来说我们写redo log之类的日志，都是对磁盘文件进行顺序写入的，也就是一行接着一行的写，不会说进行随机的读写，那么一般普通磁盘的顺序写入的吞吐量每秒都可以达到200MB左右。所以通常而言，机器的磁盘吞吐量都是足够承载高并发请求的。

  - **latency：**这个指标说的是往磁盘里写入一条数据的延迟

#### 压测的时候要关注的其他性能指标

- **CPU负载：**CPU负载是一个很重要的性能指标，因为假设你数据库压测到了每秒处理3000请求了，可能其他的性能指标都还正常，但是此时CPU负载特别高，那么也说明你的数据库不能继续往下压测更高的QPS了，否则CPU是吃不消的

- **网络负载：**这个主要是要看看你的机器带宽情况下，在压测到一定的QPS和TPS的时候，每秒钟机器的网卡会输入多少MB数据，会输出多少MB数据，因为有可能你的网络带宽最多每秒传输100MB的数据，那么可能你的QPS到1000的时候，网卡就打满了，已经每秒传输100MB的数据了，此时即使其他指标都还算正常，但是你也不能继续压测下去了

  宽带：即接入到广域网的线路，可简单理解为电信接的光纤接入，或者一条公路。

  带宽：接入宽带的理论网速上限，又分上行（即流出）带宽和下行（即流入）带宽，比如常说的100Mbps家庭宽带，就是说这条接入线路的最大下载（下行）速度为100Mbps（12.5MB/s），上行一般会比较小很多，可能只有5Mbps。理解成公路的宽度就好了。

  网速：当前网络的数据流量速度，最小0MB/s，最大不超过带宽上限。可想象成公路上的车流量。

  ```xml
  	一、带宽是什么在电子学领域里，带宽是用来描述频带宽度的。但是在数字传输方面，也常用带宽来衡量传输数据的能力。用它来表示单位时间内（一般以“秒”为单位）传输数据容量的大小，表示吞吐数据的能力。这也意味着，宽的带宽每秒钟可以传输更多的数据。所以我们一般也将“带宽”称为“数据传输率”。上网的时候，总想知道自己的网速是多少，实际上这就是网络带宽。带宽的单位一般有两种表现形式：第一种是B/s、KB/s或MB/s，表示单位时间（秒）内传输的数据量（字节、千字节、兆字节）；第二种是bps（或称b/s）、Kbps（或称Kb/s）或Mbps（或称Mb/s），表示单位时间（秒）内传输的数据量（比特、千比特、兆比特）。这两种带宽的换算公式是：1 B/s=8 bps（b/s）、1 KB/s=8 Kbps（Kb/s）、1 MB/s=8 Mbps（Mb/s）。
  	二、宽带是什么宽带并没有很严格的定义。从一般的角度理解，它是能够满足人们感观所能感受到的各种媒体在网络上传输所需要的带宽，因此它也是一个动态的、发展的概念。是指在同一传输介质上，使用特殊的技术或者设备，可以利用不同的频道进行多重（并行）传输，并且速率在256Kbps以上，至于到底多少速率以上算作宽带，目前没有国际标准，有人说大于56K就是宽带，有人说1Mbps以上才算宽带，这里我们按照约定俗成和网络多媒体视频数据量来考量为256K。因此与传统的互联网接入技术相比，宽带接入技术最大的优势就是其带宽速率远远超过56Kbps拨号。宽带是一种业务，带宽是传输速度。
  	三、网速是什么网速一般是指电脑或手机上网时，上传和下载数据时，请求和返回数据所用的时间长短。运营商产品介绍里提及的宽带网速，指的是用户端Modem至电信宽带接入设备（DSLAM）之间的物理接口速率。且由ADSL的技术特性决定了上下行速率不同。电信业务中提到的网速为1M、2M、3M、4M等是以数据通信的字位作为单位计算的。所以电脑软件显示的下载速度为200KB时，实际线路连接速率不小于1.6Mbit（1600Kbit）。考虑到数据传输中的各种损耗和电脑终端的性能，网速是不可能达到理论值的。网速的实际参考值如下：1M带宽正常下载速率在75-125KBs之间2M带宽正常下载速率在150-250KBs之间3M带宽正常下载速率在225-375KBs之间4M带宽正常下载速率在300-500KBs之间，以此类推。
  	四、流量是什么所谓流量，是指单位时间内流经封闭管道或明渠有效截面的流体量，又称瞬时流量。通常说的网站流量（traffic）是指网站的访问量，是用来描述访问一个网站的用户数量以及用户所浏览的网页数量等指标，常用的统计指标包括网站的独立用户数量、总用户数量（含重复访问者）、网页浏览数量、每个用户的页面浏览数量、用户在网站的平均停留时间等。
  ```

  **一、带宽是什么**
  在电子学领域里，带宽是用来描述频带宽度的。但是在数字传输方面，也常用带宽来衡量传输数据的能力。用它来表示单位时间内（一般以“秒”为单位）传输数据容量的大小，表示吞吐数据的能力。这也意味着，宽的带宽每秒钟可以传输更多的数据。所以我们一般也将“带宽”称为“数据传输率”。
  上网的时候，总想知道自己的网速是多少，实际上这就是网络带宽。

  **带宽的单位一般有两种表现形式：**
  第一种是B/s、KB/s或MB/s，表示单位时间（秒）内传输的数据量（字节、千字节、兆字节）；
  第二种是bps（或称b/s）、Kbps（或称Kb/s）或Mbps（或称Mb/s），表示单位时间（秒）内传输的数据量（比特、千比特、兆比特）。

  **这两种带宽的换算公式是：**
  1 B/s=8 bps（b/s）、1 KB/s=8 Kbps（Kb/s）、1 MB/s=8 Mbps（Mb/s）。

  **二、宽带是什么**

  宽带并没有很严格的定义。从一般的角度理解，它是能够满足人们感观所能感受到的各种媒体在网络上传输所需要的带宽，因此它也是一个动态的、发展的概念。是指在同一传输介质上，使用特殊的技术或者设备，可以利用不同的频道进行多重（并行）传输，并且速率在256Kbps以上，至于到底多少速率以上算作宽带，目前没有国际标准，有人说大于56K就是宽带，有人说1Mbps以上才算宽带，这里我们按照约定俗成和网络多媒体视频数据量来考量为256K。因此与传统的互联网接入技术相比，宽带接入技术最大的优势就是其带宽速率远远超过56Kbps拨号。
  宽带是一种业务，带宽是传输速度。

  **三、网速是什么**
  网速一般是指电脑或手机上网时，上传和下载数据时，请求和返回数据所用的时间长短。
  运营商产品介绍里提及的宽带网速，指的是用户端Modem至电信宽带接入设备（DSLAM）之间的物理接口速率。且由ADSL的技术特性决定了上下行速率不同。
  电信业务中提到的网速为1M、2M、3M、4M等是以数据通信的字位作为单位计算的。所以电脑软件显示的下载速度为200KB时，实际线路连接速率不小于1.6Mbit（1600Kbit）。
  考虑到数据传输中的各种损耗和电脑终端的性能，网速是不可能达到理论值的。
  **网速的实际参考值如下：**
  1M带宽正常下载速率在75-125KBs之间
  2M带宽正常下载速率在150-250KBs之间
  3M带宽正常下载速率在225-375KBs之间
  4M带宽正常下载速率在300-500KBs之间，以此类推。

  **四、流量是什么**
  所谓流量，是指单位时间内流经封闭管道或明渠有效截面的流体量，又称瞬时流量。
  通常说的网站流量（traffic）是指网站的访问量，是用来描述访问一个网站的用户数量以及用户所浏览的网页数量等指标，常用的统计指标包括网站的独立用户数量、总用户数量（含重复访问者）、网页浏览数量、每个用户的页面浏览数量、用户在网站的平均停留时间等。

- **内存负载：**这个就是看看在压测到一定情况下的时候，你的机器内存耗费了多少，如果说机器内存耗费过高了，说明也不能继续压测下去了

#### [数据库压测工具sysbench](https://www.jianshu.com/p/e2a4887a4edd)

sysbench可以自动帮你在数据库里构造出来大量的数据，想要多少数据，他就自动给你构造出来多少条数据。然后这个工具接着可以模拟几千个线程并发的访问你的数据库，模拟使用各种各样的SQL语句来访问你的数据库，包括模拟出来各种事务提交到你的数据库里去，甚至可以模拟出几十万的TPS去压测你的数据库。

- 在linux上安装sysbench工具

  ```sql
  yum -y install sysbench
  sysbench --version
  ```

- 数据库压测的测试用例

  创建好一个测试库test_db,同时创建好对应的测试账号，可以叫做test_user，密码也是test_user，让这个用户有权限可以访问test_db。然后我们将要基于sysbench构建20个测试表，每个表里有100万条数据，接着使用10个并发线程去对这个数据库发起访问，连续访问5分钟，也就是300秒，然后对其进行压力测试。

- 基于sysbench构造测试表和测试数据

  ```shell
  sysbench --db-driver=mysql --time=300 --threads=10 --report-interval=1 --mysql-host=127.0.0.1 --mysql-port=3306 --mysql-user=test_user --mysql-password=test_user --mysql-db=test_db --tables=20 --table_size=1000000 oltp_read_write 
  --db-ps-mode=disable prepare
  #----------------------------------------------------------------------------------------------------------------------------
  --db-driver=mysql：这个很简单，就是说他基于mysql的驱动去连接mysql数据库，你要是oracle，或者sqlserver，那自然就是其他的数据库的驱动了
  --time=300：这个就是说连续访问300秒
  --threads=10：这个就是说用10个线程模拟并发访问
  --report-interval=1：这个就是说每隔1秒输出一下压测情况
  --mysql-host=127.0.0.1 --mysql-port=3306 --mysql-user=test_user --mysql-password=test_user：MySQL连接信息
  --mysql-db=test_db --tables=20 --table_size=1000000：在test_db这个库里，构造20个测试表，每个测试表里构造100万条测试数据，测试表的名字会是类似于sbtest1，sbtest2这个样子的
  oltp_read_write：这个就是说，执行oltp数据库的读写测试
  --db-ps-mode=disable：这个就是禁止ps模式
  sysbench 的测试过程一般分为三个阶段[prepare|run|cleanup]：
  prepare：准备阶段，准备测试数据。参照这个命令的设置去构造出来我们需要的数据库里的数据，他会自动创建20个测试表，每个表里创建100万条测试数据
  run：执行测试阶段。参照这个命令的设置测试数据库
  cleanup：清理垃圾数据阶段。
  #----------------------------------------------------------------------------------------------------------------------------
  ```

#### 对数据库进行360度的全方位测试

测试数据库的综合读写TPS，使用的是oltp_read_write模式

```shell
sysbench --db-driver=mysql --time=300 --threads=10 --report-interval=1 --mysql-host=127.0.0.1 --mysql-port=3306 --mysql-user=test_user --mysql-password=test_user --mysql-db=test_db --tables=20 --table_size=1000000 oltp_read_write --db-ps-mode=disable run
```

测试数据库的只读性能，使用的是oltp_read_only模式

```shell
sysbench --db-driver=mysql --time=300 --threads=10 --report-interval=1 --mysql-host=127.0.0.1 --mysql-port=3306 --mysql-user=test_user --mysql-password=test_user --mysql-db=test_db --tables=20 --table_size=1000000 oltp_read_only --db-ps-mode=disable run
```

测试数据库的删除性能，使用的是oltp_delete模式

```shell
sysbench --db-driver=mysql --time=300 --threads=10 --report-interval=1 --mysql-host=127.0.0.1 --mysql-port=3306 --mysql-user=test_user --mysql-password=test_user --mysql-db=test_db --tables=20 --table_size=1000000 oltp_delete --db-ps-mode=disable run
```

测试数据库的更新索引字段的性能，使用的是oltp_update_index模式

```shell
sysbench --db-driver=mysql --time=300 --threads=10 --report-interval=1 --mysql-host=127.0.0.1 --mysql-port=3306 --mysql-user=test_user --mysql-password=test_user --mysql-db=test_db --tables=20 --table_size=1000000 oltp_update_index --db-ps-mode=disable run
```

测试数据库的更新非索引字段的性能，使用的是oltp_update_non_index模式

```shell
sysbench --db-driver=mysql --time=300 --threads=10 --report-interval=1 --mysql-host=127.0.0.1 --mysql-port=3306 --mysql-user=test_user --mysql-password=test_user --mysql-db=test_db --tables=20 --table_size=1000000 oltp_update_non_index --db-ps-mode=disable run
```

测试数据库的插入性能，使用的是oltp_insert模式

```shell
sysbench --db-driver=mysql --time=300 --threads=10 --report-interval=1 --mysql-host=127.0.0.1 --mysql-port=3306 --mysql-user=test_user --mysql-password=test_user --mysql-db=test_db --tables=20 --table_size=1000000 oltp_insert --db-ps-mode=disable run
```

测试数据库的写入性能，使用的是oltp_write_only模式

```shell
sysbench --db-driver=mysql --time=300 --threads=10 --report-interval=1 --mysql-host=127.0.0.1 --mysql-port=3306 --mysql-user=test_user --mysql-password=test_user --mysql-db=test_db --tables=20 --table_size=1000000 oltp_write_only --db-ps-mode=disable run
```

使用上面的命令，sysbench工具会根据你的指令构造出各种各样的SQL语句去更新或者查询你的20张测试表里的数据，同时监测出你的数据库的压测性能指标，最后完成压测之后，可以执行下面的cleanup命令，清理数据。

```shell
sysbench --db-driver=mysql --time=300 --threads=10 --report-interval=1 --mysql-host=127.0.0.1 --mysql-port=3306 --mysql-user=test_user --mysql-password=test_user --mysql-db=test_db --tables=20 --table_size=1000000 oltp_read_write --db-ps-mode=disable cleanup
```

#### 压测结果分析

```shell
#按照我们上面的命令，我们是让他每隔1秒都会输出一次压测报告的，此时他每隔一秒会输出类似下面的一段东西
[ 22s ] thds: 10 tps: 380.99 qps: 7312.66 (r/w/o: 5132.99/1155.86/1321.35) lat (ms, 95%): 21.33 err/s: 0.00 reconn/s:0.00
```

```go
首先他说的这是第22s输出的一段压测统计报告，然后是其他的一些统计字段：
thds: 10 //这个意思就是有10个线程在压测
tps: 380.99 //这个意思就是每秒执行了380.99个事务
qps: 7610.20 //这个意思就是每秒可以执行7610.20个请求
(r/w/o: 5132.99/1155.86/1321.35) //这个意思就是说，在每秒7610.20个请求中，有5132.99个请求是读请求，1155.86个请求是写请求，1321.35个请求是其他的请求，就是对QPS进行了拆解
lat (ms, 95%): 21.33，这个意思就是说，95%的请求的延迟都在21.33毫秒以下
err/s: 0.00 reconn/s: 0.00，这两个的意思就是说，每秒有0个请求是失败的，发生了0次网络重连

最后会显示一个总的压测报告
SQL statistics:
    queries performed:
        read: 1480084 // 这就是说在300s的压测期间执行了148万多次的读请求
        write: 298457 // 这是说在压测期间执行了29万多次的写请求
        other: 325436 // 这是说在压测期间执行了30万多次的其他请求
        total: 2103977 // 这是说一共执行了210万多次的请求
    // 这是说一共执行了10万多个事务，每秒执行350多个事务
    transactions: 105180( 350.6 per sec. )
    // 这是说一共执行了210万多次的请求，每秒执行7000+请求
    queries: 2103977 ( 7013.26 per sec. )
    ignored errors: 0 (0.00 per sec.)
    reconnects: 0 (0.00 per sec.)
// 下面就是说，一共执行了300s的压测，执行了10万+的事务
General staticstics:
    total time: 300.0052s
    total number of events: 105180
Latency (ms):
    min: 4.32 // 请求中延迟最小的是4.32ms
    avg: 13.42 // 所有请求平均延迟是13.42ms
    max: 45.56 // 延迟最大的请求是45.56ms
    95th percentile: 21.33 // 95%的请求延迟都在21.33ms以内
	sum: 600089.85 // 请求中总的延迟
Threads fairness:
    events (avg/stddev):           1974.9000/4.18 // 请求中事务的平均/标准偏差
    execution time (avg/stddev):   60.0090/0.01 //执行时间的平均/标准偏差
```

#### 除了QPS和TPS以外，我们还需要观察机器的性能

使用sysbench这个工具非常方便的去对数据库进行压测，压测过后其实大家就会看到自己的数据库大概能抗下多少QPS和TPS。另外一个压测时的技巧，就是上一篇文章里我们是使用了10个线程去压测数据库，如果你的机器性能很高，然后你觉得10个线程没法压测出来数据库真实的最高负载能力，你其实可以在sysbench中不停的增加线程的数量，比如使用20个线程，甚至100个线程去并发的访问数据库，直到发现数据库的QPS和TPS上不去了。

就是在压测的时候我们需要不停的增加线程的数量去让数据库承载更高的QPS，一直到最后看看数据库到底最高可以承载多高的QPS。

首先，假设数据库当前抗下了每秒2000的QPS，同时这个时候机器的CPU负载、内存负载、网络负载、磁盘IO负载，都在正常的范围内，负载相对较高一些，但是还没有达到这些硬件的极限，那么我们可以认为这台数据库在高峰期抗到每秒2000的QPS，是没有问题的。但是如果你一直不停的在压测过程中增加sysbench的线程数量。

然后数据库此时勉强抗到了每秒5000的QPS了，但是这个时候你发现机器的CPU已经满负荷运行了，内存使用率特别高，内存都快要不够了，然后网络带宽几乎被打满了，磁盘IO的等待时间特别长，这个时候说明机器已经到了极致了，再搞下去，机器都快挂了。

所以说，在压测的过程中，必须是不停的增加sysbench的线程数量，持续的让数据库承载更高的QPS，同时密切关注机器的CPU、内存、磁盘和网络的负载情况，在硬件负载情况比较正常的范围内，哪怕负载相对较高一些，也还是可以继续增加线程数量和提高数据库的QPS的。然后当你不停的增加线程数量，发现在数据库抗下一个QPS的数值的同时，机器的CPU、内存、网络和磁盘的负载已经比较高了，到了一个有一定风险的临界值的了，此时就不能继续增加线程数量和提高数据库抗下的QPS了。

#### 压测时如何观察机器的CPU负载情况

最常用的监测linux机器性能的命令，就是top命令，直接在linux命令行只能够输入top指令就可以了

```shell
top - 15:52:00 up 42:35, 1 user, load average: 0.15, 0.05, 0.01
#这行信息是最直观可以看到机器的cpu负载情况的，首先15:52:00指的是当前时间，up 42:35指的是机器已经运行了多长时间，1 user就是说当前机器有1个用户在使用。最重要的是load average(平均负载): 0.15, 0.05, 0.01这行信息，他说的是CPU在1分钟、5分钟、15分钟内的平均负载情况
```

这里要着重解释一下这个CPU负载的概念和含义，

假设我们是一个4核的CPU，此时如果你的CPU负载是0.15，这就说明，4核CPU中连一个核都没用满，4核CPU基本都很空闲，没啥人在用。如果你的CPU负载是1，那说明4核CPU中有一个核已经被使用的比较繁忙了，另外3个核还是比较空闲一些。要是CPU负载是1.5，说明有一个核被使用繁忙，另外一个核也在使用，但是没那么繁忙，还有2个核可能还是空闲的。如果你的CPU负载是4，那说明4核CPU都被跑满了，如果你的CPU负载是6，那说明4核CPU被繁忙的使用还不够处理当前的任务，很多进程可能一直在等待CPU去执行自己的任务。

所以上面看到的load average实际上就是CPU在最近1分钟，5分钟，15分钟内的平均负载数值，上面都是0.15之类的，说明CPU根本就没怎么用。但是如果你在压测的过程中，发现4核CPU的load average已经基本达到3.5，4了，那么说明几个CPU基本都跑满了，在满负荷运转，那么此时你就不要再继续提高线程的数量和增加数据库的QPS了，否则CPU负载太高是不合理的。

#### 压测时如何观察机器的内存负载情况

在你执行top命令之后，中间我们跳过几行内容，可以看到如下一行内容,或者使用free命令

```shell
Mem: 33554432k total, 20971520k used, 12268339 free, 307200k buffers
#明显可以看出来就是总内存大概有32GB，已经使用了20GB左右的内存，还有10多G的内存是空闲的，然后有大概300MB左右的内存用作OS内核的缓冲区了
```

对于内存而言，同样是要在压测的过程中紧密的观察，一般来说，如果内存的使用率在80%以内，基本都还能接受，在正常范围内，但是如果你的机器的内存使用率到了70%~80%了，就说明有点危险了，此时就不要继续增加压测的线程数量和QPS了，差不多就可以了

#### [压测时如何观察机器的磁盘IO情况](https://commandnotfound.cn/linux/1/272/dstat-%E5%91%BD%E4%BB%A4)

使用dstat -d命令

```shell
-dsk/total-
 read  writ
3234B   14k
   0  4096B
   0   116k
   0     0 
   0   212k^C
#存储的IO吞吐量是每秒钟读取103kb的数据，每秒写入211kb的数据，像这个存储IO吞吐量基本上都不算多的，因为普通的机械硬盘都可以做到每秒钟上百MB的读写数据量
```

使用命令：dstat -r

```shell
--io/total-
 read  writ
0.08  1.90 
   0  3.00 
   0     0 
   0  1.00 
   0  3.00 
#意思就是读IOPS和写IOPS分别是多少，也就是说随机磁盘读取每秒钟多少次，随机磁盘写入每秒钟执行多少次，大概就是这个意思，一般来说，随机磁盘读写每秒在两三百次都是可以承受的
```

所以在这里，我们就需要在压测的时候密切观察机器的磁盘IO情况，如果磁盘IO吞吐量已经太高了，都达到极限的每秒上百MB了，或者随机磁盘读写每秒都到极限的两三百次了，此时就不要继续增加线程数量了，否则磁盘IO负载就太高了

#### 压测时观察网卡的流量情况

使用dstat -n命令

```shell
-net/total-
 recv  send
   0     0 
6458B   20k
8086B 6412B
6691B 7991B
  15k   18k
4450B 5500B
#每秒钟网卡接收到流量有多少kb，每秒钟通过网卡发送出去的流量有多少kb，通常来说，如果你的机器使用的是千兆网卡，那么每秒钟网卡的总流量也就在100MB左右，甚至更低一些
```

所以我们在压测的时候也得观察好网卡的流量情况，如果网卡传输流量已经到了极限值了，那么此时你再怎么提高sysbench线程数量，数据库的QPS也上不去了，因为这台机器每秒钟无法通过网卡传输更多的数据了

#### 压测总结

你必须不停的增加sysbench的线程数量，增加数据库抗下的QPS，同时通过各种命令观察机器的CPU、内存、磁盘和网络的负载情况，如果你发现某个硬件负载已经很高了，此时就可以不再提高数据库的QPS了。**在硬件的一定合理的负载范围内，把数据库的QPS提高到最大，这就是数据库压测的时候最合理的一个极限QPS值**，而不是不管机器的各个硬件的负载，盲目的不停的增加sysbench的线程数量，不停的让数据库增加可以抗下的QPS的数值。

### 搭建基于Prometheus+Grafana的可视化监控平台

Prometheus其实就是一个监控数据采集和存储系统，他可以利用监控数据采集组件（比如mysql_exporter）从你指定的MySQL数据库中采集他需要的监控数据，然后他自己有一个时序数据库，他会把采集到的监控数据放入自己的时序数据库中，其实本质就是存储在磁盘文件里

Grafana就是一个可视化的监控数据展示系统，他可以把Prometheus采集到的大量的MySQL监控数据展示成各种精美的报表，让我们可以直观的看到MySQL的监控情况。

对你开发出来的各种Java系统、中间件系统，都可以使用这套组合去进行可视化的监控，无非就是让Prometheus去采集你的监控数据，然后用Grafana展示成报表而已。

搭建参考

https://www.jb51.net/article/204660.htm

https://www.cnblogs.com/miaocbin/p/12009974.html

https://blog.csdn.net/aixiaoyang168/article/details/81354059

https://edu.51cto.com/course/16802.html

### 小思考题

- 给你一台4核8G的机器，他可以抗到每秒几千甚至每秒几万的并发请求吗？

  其实这个是不一定的，因为一台机器到底每秒钟可以抗下多少并发请求，跟CPU、内存、磁盘IO、网络带宽，都是有关系的。举个例子，之前在我们的一个项目的生产环境中，据我们观察，一台4核8G的机器如果每秒抗下500+的请求，那么他的CPU负载就已经很高了，基本上最多可能也就是去抗下每秒1000+的请求，而且那个时候CPU负载基本会打满，机器有挂掉的风险。另外如果你的系统的业务逻辑特别的吃内存，也许你一台4核8G的机器跑到每秒几百的请求，内存使用率就很高了，而且JVMGC频率可能会非常的高，所以此时也很难继续提升并发请求了。所以其实你一台机器是不可能无限制的让他增加可以抗下的并发请求的

- 如果一个交易系统拆分为了很多服务，那么每个服务每秒接收的并发请求是QPS还是TPS呢？

  这个明显是QPS，因为每个服务就负责干自己的一些事儿，其实对他来说，每秒并发请求数量就是QPS。

- 对于多个服务组成的一个大的交易系统而言，这个交易系统每秒可以完成多少笔交易，这是QPS还是TPS呢？

  其实这个你可以认为是TPS的概念，因为一笔交易需要调用多个服务来完成，所以一笔交易的完成其实就类似数据库里的一个

  事务，他涵盖了很多服务的请求调用，所以每秒完成多少笔交易，你可以用TPS来形容。

## 实战案例

### MySQL索引设计实战

```mysql
select xx from user_info where age between 20 and 25 order by score limit 10
```

- 问题一在where和order by出现索引设计冲突

往往在类似这种SQL里，你的where筛选和order by排序实际上大部分情况下是没法都用到索引的.假设你针对age和score分别设计了两个索引，但是在你的SQL里假设基于age索引进行了筛选，是没法利用另外一个score索引进行排序的

- 在where和order by出现索引设计冲突，鱼与熊掌不可兼得的时候到底是针对where去设计索引，还是针对order by设计索引？

一般这种时候往往都是让where条件去使用索引来快速筛选出来一部分指定的数据，接着再进行排序，最后针对排序后的数据拿出来一页数据。因为基于索引进行where筛选往往可以最快速度筛选出你要的少部分数据，如果筛选出来的数据量不是太大的话，那么后续排序和分页的成本往往不会太大！

- where后面出现基数非常小的几个字段

基数太低的字段最好别放到索引里去，那省份、城市和性别，都是基数非常小的几个字段，可选的值就那么几个，为什么要放到索引里去？这是个好问题，但是规则是死的，人是活的。

假设你就因为省份、城市和性别几个字段的基数太小了，此时就不把他们几个包含到联合索引里去，那么你实际查询的时候都要基于这几个字段去搜索，此时你就只能把这几个字段放在where条件的最后，那么最后每次查询都必须要先用联合索引查询出来一部分数据，接着数据加载到内存里去，再根据where条件最后的省份、城市和性别几个字段进行过滤筛选，每次查询都得多这么一个步骤。所以与其如此，还不如就把省份、城市和性别三个字段，放在联合索引的最左侧，这样跟其他字段组合联合索引后，让大部分的查询都可以直接通过索引树就可以把where条件指定的数据筛选出来了。

```mysql
#那如果把索引设计成（province, city, sex, age），此时你的语句写成
where province=xx and city=xx and age>=xx and age<=xx #也是没法让age用上索引去筛选的，因为city和age中间差了一个sex，所以此时就不符合最左侧连续多个字段的原则了
```

此时你的语句写成where province=xx and city=xxand age>=xx and age<=xx，也是没法让age用上索引去筛选的，因为city和age中间差了一个sex，所以此时就不符合最左侧连续多个字段的原则了

针对这样的一些频繁使用的包含枚举值范围的一些字段，也完全可以加入到联合索引里去，可以设计成（province, city, sex, hobby, character, age）这样的一个联合索引，此时假设出现了这样一个查询，按照省份、城市、性格和年龄进行搜索，此时SQL:

```mysql
where province=xx and city=xx and sex in(xx, xx) andhobby in (xx, xx, xx, xx) and character=xx and age>=xx and age<=xx
```

- 范围字段必须要放在联合索引的最后一个呢？

很简单，因为之前我们讲索引使用规则的时候说过，假设你where语句里有等值匹配，还有范围匹配，此时必须是先让联合索引最左侧开始的多个字段使用等值匹配，接着最后一个字段是范围匹配。就比如上面的语句where province=xx and city=xx and sex in(xx, xx) and hobby in (xx, xx, xx, xx)and character=xx and age>=xx and age<=xx，他们完全是按照联合索引最左侧开始的，province、city、sex、hobby、character都是联合索引最左侧开始的多个字段，他们都是等值匹配，然后最后一个age字段使用的是范围匹配，这种就是可以完全用上索引的。但是假设你要是在联合索引里把age放在中间的位置，设计一个类似（province, city, sex, age, hobby,character）的联合索引，接着SQL写成where province=xx and city=xx and sex in(xx, xx) andage>=xx and age<=xx and hobby in (xx, xx, xx, xx) and character=xx的话，那么不好意思，只有province, city, sex, age几个字段可以用上索引。因为在SQL里，一旦你的一个字段做范围查询用到了索引，那么这个字段接下来的条件都不能用索引了，这就是规则

所以说，实际设计索引的时候，必须把经常用做范围查询的字段放在联合索引的最后一个，才能保证你SQL里每个字段都能基于索引去查询。

- 筛选最近7天登录过的用户

  表里有这么一个字段，latest_login_time你要是在where条件里加入这么一个latest_login_time <= 7天内语句，肯定这个是没法用上索引了。因

  为你这里必然会用一些计算或者是函数，才能进行一些时间的比对。也就是说，即使你索引设计成这样：（province, city, sex, hobby, character, age,

  latest_login_time），然后你的where语句写成这样：where xx xxx and age>=xx and age<=xxx andlatest_login_time>=xx，虽然age和latest_login_time都在联合索引里，但是按照规则，只有age范围查询可以用到索引，latest_login_time始终是用不到索引的。此时你完全可以设计一个字段为：does_login_in_latest_7_days，也就是说，这个人是否在最近7天内登录过APP。假设在7天内登录了这个APP，那么这个字段就是1，否则超过7天没登录，这个字段就是0！这样就把一个时间字段转换为了一个枚举值的字段。接下来的解决方案就简单化了，可以设计一个联合索引为：（province, city, sex, hobby, character,does_login_in_latest_7_days, age，然后搜索的时候，一定会在where条件里带上一个does_login_in_latest_7_days=1，最后再跟上age范围查询，这样就可以让你的where条件里的字段都用索引来筛选。

- 辅助索引

  那种基数很低的字段再加上排序字段单独额外设计一个。专门用于解决where条件里都是基数低的字段，然后还要排序后分页的问题，比如说就可以设计一个联合索引为：（sex, score）

  此时因为where条件里的字段是等值匹配，而且还是等于某个常量值，所以虽然order by后跟的score字段是（sex, score）索引里的第二个字段，order by没有从索引最左侧字段开始排列，但是他也可以使用到索引来排序。因为具体到使用索引的层面，他会先对where条件里的sex='female'在索引树里筛选到这部分数据，接着在sex='female'的数据里，这些数据实际上都是排列在一起的，因为在索引里，会按照sex和score两个字段去进行排序，所以sex='female'的数据都是在一块儿的。然后找到这部分数据之后，接着就可以确定，这部分数据肯定是按照score字段进行排序的，此时就可以按照score字段值的顺序，去读取你的limit语句指定的数据分页出来就可以了

- 低基数字段筛选+评分排序的查询场景

  同时针对一些低基数字段筛选+评分排序的查询场景，可以设计类似（sex, score）的**辅助索引**来应对，让他快速定位到一大片低基数字段对应的数据，然后按照索引顺序去走limit语句获取指定分页的数据，速度同样会很快

**核心重点就是，尽量利用一两个复杂的多字段联合索引，抗下你80%以上的 查询，然后用一两个辅助索引抗下剩余20%的非典型查询，保证你99%以上的查询都能充分利用索引，就能保证你的查询速度和性能！**

### 千万级用户场景下的系统SQL调优

- 案例背景

  通过一些条件**筛选出大量的用户**，接着针对这些用户做一些推送。用户是日活百万级的，注册用户是千万级的，而且如果还没有进行分库分表的话

- SQL

  ```mysql
  //查询一下最近一次登录时间小于某个时间点的用户
  SELECT id, name FROM users WHERE id IN (SELECT user_id FROM users_extent_info WHERE latest_login_time < xxxxx)
  
  SELECT COUNT(id) FROM users WHERE id IN (SELECT user_id FROM users_extent_info WHERE latest_login_time < xxxxx)
  ```

  一般运行这类SQL之前，都会先跑一个count聚合函数，看看有多少条。然后内存里做一个小批量多批次读取数据的操作，比如判断如果在1000条以内，那么就一下子读取出来，如果超过1000条，可以通过LIMIT语句，每次就从这个结果集里查1000条数据，查1000条就做一次批量PUSH，再查下一波1000条。

- 问题

  就是在千万级数据量的大表场景下，COUNT聚合函数的SQL直接跑出来耗时几十秒的速度

- 执行计划

  ```mysql
  - EXPLAIN SELECT COUNT(id) FROM users WHERE id IN (SELECT user_id FROM users_extent_info WHERE latest_login_time < xxxxx)
  
  +----+-------------+-------+------------+-------+---------------+----------+---------+------+
  
  | id | select_type | table | type | key | rows | fifiltered | Extra |
  
  +----+-------------+-------+------------+-------+---------------+----------+---------+------+
  
  | 1 | SIMPLE | | ALL | NULL | NULL | 100.00 | NULL |
  
  | 1 | SIMPLE | users | ALL | NULL | 49651 | 10.00 | Using where; Using join buffffer(Block Nested
  
  Loop) |
  
  | 2 | MATERIALIZED | users_extent_info | range | idx_login_time | 4561 | 100.00 | NULL |+----+-------------+-------+------------+-------+---------------+----------+---------+------+
  ```

- 问题分析

  从上面的执行计划，我们可以清晰的看到这条SQL语句的一个执行过程

  - 首先，针对子查询，是执行计划里的第三行实现的，他清晰的表明，针对users_extent_info，使用了idx_login_time这个索引，做了range类型的索引范围扫描，查出来了4561条数据，没有做其他的额外筛选，所以fifiltered是100%。MATERIALIZED表明了这里把子查询的4561条数据代表的结果集进行了物化，物化成了一个临时表，这个临时表物化，一定是会把4561条数据临时落到磁盘文件里去的，这个过程其实就挺慢的
  - 然后第二条执行计划表明，接着就是针对users表做了一个全表扫描，在全表扫描的时候扫出来了49651条数据，同时大家注意看Extra字段，显示了一个Using join buffffer的信息，这个明确表示，此处居然在执行join操作
  - 接着看执行计划里的第一条，这里他是针对子查询产出的一个物化临时表，也就是，做了一个全表查询，把里面的数据都扫描了一遍

  原因就是在让users表的每一条数据，都要去跟物化临时表里的数据进行join，所以针对users表里的每一条数据，只能是去全表扫描一遍物化临时表，找找物化临时表里哪条数据是跟他匹配的，才能筛选出来一条结果。

  第二条执行计划的全表扫描的结果表明是一共扫到了49651条数据，但是全表扫描的过程中，因为去跟物化临时表执行了一个join操作，而物化临时表里就4561条数据，所以最终第二条执行计划的fifiltered显示的是10%，也就是说，最终从users表里筛选出了也是4000多条数据。

- 排查问题

  其实很明显了，首先对子查询的结果做了一次物化临时表，落地磁盘了，接着他还全表扫描了users表的所有数据，每一条数据居然跑到一个没有索引的物化临时表里再做一次全表扫描找匹配数据。临时表物化、对users表的全表扫描耗、对users表的每一条数据跑到物化临时表里做全表扫描都是挺耗时的。几乎就没怎么用到索引。

  为什么会出现上述的一个全表扫描users表，然后跟物化临时表做join，join的时候还要全表扫描物化临时表的过程？

  这里交大家一个技巧，就是在执行完上述SQL的EXPLAIN命令，看到执行计划之后，可以执行一下**[show warnings](https://www.lanmper.cn/mysql/t7966.html)**命令。

  /* select#1 */ select count( d2. users . user_id `) AS COUNT(users.user_id)`from d2 . users users semi join xxxxxx，下面省略一大段内容，因为可读性实在不高，大家关注的应该是这里的**semi join**这个关键字。这里就显而易见了！MySQL在这里，生成执行计划的时候，自动就把一个普通的IN子句，“优化”成了基于semi join来进行IN+子查询的操作

  对users表里每一条数据，去对物化临时表全表扫描做semijoin，不需要把users表里的数据真的跟物化临时表里的数据join上。只要users表里的一条数据，在物化临时表里可以找到匹配的数据，那么users表里的数据就会返回，这就叫做semi join，他是用来筛选的。

- 解决方案(可以参考，不一定就快)

  - 关闭掉半连接优化

    ```mysql
    SET optimizer_switch='semijoin=off' -- 关闭掉半连接优化
    ```

    此时执行EXPLAIN命令看一下此时的执行计划，发现此时会恢复为一个正常的状态。就是有一个SUBQUERY的子查询，基于range方式去扫描索引搜索出4561条数据，接着有一个PRIMARY类型的主查询,直接是基于id这个PRIMARY主键聚簇索引去执行的搜索

  - 修改语义

    生产环境是不能随意更改这些设置的。所以尽可能的去改变SQL语句的结构和格式

    ```mysql
    SELECT COUNT(id)
    FROM users
    WHERE (id IN (SELECT user_id FROM users_extent_info WHERE latest_login_time < xxxxx) 
    OR id IN (SELECT user_id FROM users_extent_info WHERE latest_login_time < -1))
    ```

    在上述写法下，WHERE语句的OR后面的第二个条件，根本是不可能成立的，因为没有数据的latest_login_time是小于-1的，所以那是不会影响SQL语义的，但是我们发现改变了SQL的写法之后，执行计划也随之改变。他并没有再进行semi join优化了，而是正常的用了子查询，主查询也是基于索引去执行的。性能一下子就提升了。

### 亿级数据量商品系统的SQL调优

- 案例背景

  MySQL数据库在选择索引的时候，选择了一个不太合适的索引，导致了性能极差，引发了慢查询。大量的慢查询，导致每一个数据库连接执行一个慢查询都要耗费很久。那这样的话，必然会导致突然过来的很多查询需要让数据库开辟出来更多的连接，因此这个时候报警也告诉我们，数据库的连接突然也暴增了，而且每个连接都打满，每个连接都要执行一个慢查询，慢查询还跑的特别慢。接着引发的问题，就是数据库的连接全部打满，没法开辟新的连接了，但是还持续的有新的查询发送过来，导致数据库没法处理新的查询，很多查询发到数据库直接就阻塞然后超时了，这也直接导致线上的商品系统频繁的报警，出现了大量的数据库查询超时报错的异常！这种情况，基本意味着你的商品数据库以及商品系统濒临于崩溃了，大量慢查询耗尽了数据库的连接资源。

- SQL

  数据库的监控里显示，每分钟的慢查询超过了10w+！！！也就是说商品系统大量的查询都变成了慢查询！！！

  select * from products where category='xx' and sub_category='xx' order by id desc limit xx,xx

  这个语句执行的商品表里大致是1亿左右的数据量，这个量级已经稳定了很长时间了，主要也就是这么多商品，但是上面的那个语句居然一执行就是几十秒！基本上数据库的连接全部被慢查询打满，一个连接要执行几十秒的SQL，然后才能执行下一个SQL，此时数据库基本就废了，没法执行什么查询了

- 问题分析

  这个表当时肯定是对经常用到的查询字段都建立好了索引的，那么针对这里简化后的SQL语句，你可以认为如下的一个索引，KEY index_category(catetory,sub_category)肯定是存在的，所以基本可以确认上面的SQL绝对是可以用上索引的。

  一旦用上了品类的那个索引，按说这个语句应该执行的速度是很快的，即使表有亿级数据，但是执行时间也最多不应该超过1s。但是现在这个SQL语句跑了几十秒，那说明他肯定就没用我们建立的那个索引。

- 排查问题

  查看执行计划，possible_keys里是有我们的index_category的，结果实际用的key不是这个索引，而是PRIMARY！！而且Extra里清晰写了Using where。到此为止，这个SQL语句为什么性能这么差，就真相大白了，他其实本质上就是在主键的聚簇索引上进行扫描，一边扫描，一边还用了where条件里的两个字段去进行筛选，所以这么扫描的话，那必然就是会耗费几十秒了！

- 解决方案(使用force index强制改变MySQL的执行计划)

  因此此时为了快速解决这个问题，就需要强制性的改变MySQL自动选择这个不合适的聚簇索引进行扫描的行为，就是使用force index语法

  ```mysql
  select * from products force index(index_category) where category='xx' and sub_category='xx' order by id desc limit xx,xx
  ```

  此时再次执行这个SQL语句，会发现他仅仅耗费100多毫秒而已！性能瞬间就提升上来了

- 后续问题

  - 为什么在这个案例中MySQL默认会选择对主键的聚簇索引进行扫描

    对于一个亿级数据量的大表来说，index_category这个二级索引也是比较大的。所以MySQL来说，他有这么一个判断，他觉得如果要是从index_category二级索引里来查找到符合where条件的一波数据，接着还得回表，回到聚簇索引里去。

    因为SQL语句是要select *的，所以这里必然涉及到一次回表操作，回到聚簇索引里去把所有字段的数据都查出来，但是在回表之前，他必然要做完order by id desc limit xx,xx这个操作

    也就是说，直接扫描主键的聚簇索引，因为聚簇索引都是按照id值有序的，所以扫描的时候，直接按order by id desc这个倒序顺序扫描过去就可以了，然后因为他知道你是limit 0,10的，也就知道你仅仅只要拿到10条数据就行了。所以他在按顺序扫描聚簇索引的时候，就会对每一条数据都采用Using where的方式，跟wherecategory='xx' and sub_category='xx'条件进行比对，符合条件的就直接放入结果集里去，最多就是放10条数据进去就可以返回了。此时MySQL认为，按顺序扫描聚簇索引，拿到10条符合where条件的数据，应该速度是很快的，很可能比使用index_category二级索引那个方案更快，因此此时他就采用了扫描聚簇索引的这种方式！

  - 为什么没使用index_category这个二级索引进行扫描？

    ```mysql
    举个例子吧，比如他根据where category='xx' and sub_category='xx'，从index_category二级索引里查找出了一大波数据。
    
    比如从二级索引里假设搂出来了几万条数据，接着因为二级索引里是包含主键id值的，所以此时他就得按照order by id desc这个排序语法，对这几万条数据基于临时磁盘文件进行fifilesort磁盘排序，排序完了之后，再按照limit xx,xx语法，把指定位置的几条数据拿出来，假设就是limit 0,10，那么就是把10条数据拿出来。拿出来10条数据之后，再回到聚簇索引里去根据id查找，把这10条数据的完整字段都查出来，这就是MySQL认为如果你使用index_category的话，可能会发生的一个情况。所以他担心的是，你根据where category='xx' and sub_category='xx'，从index_category二级索引里查出来的数据太多了，还得在临时磁盘里排序，可能性能会很差，因此MySQL就把这种方式判定为一种不太好的方式，因此他才没使用index_category这个二级索引进行扫描。
    ```

  - 即使用了聚簇索引，为什么这个SQL以前没有问题，现在突然就有问题了？

    在商品管理的时候加了几种商品分类和子类，但是这几种分类和子类的组合其实没有对应的商品。 where category='新分类' and sub_category='新子类'这个条件实际上是查不到任何数据的。所以说，底层在扫描聚簇索引的时候，扫来扫去都扫不到符合where条件的结果，一下子就把聚簇索引全部扫了一遍，等于是上亿数据全表扫描了一遍，都没找到符合where category='新分类' and sub_category='新子类'这个条件的数据。也正是因为如此，才导致这个SQL语句频繁的出现几十秒的慢查询，进而导致MySQL连接资源打满，商品系统崩溃！

### 数十亿数量级评论系统的SQL调优实战

- 案例背景

  商品评论系统的数据量非常大，拥有多达十亿量级的评论数据，所以当时对这个评论数据库，需要做分库分表的，基本上分完库和表过后，单表的评论数据在百万级别。每一个商品的所有评论都是放在一个库的一张表里的，这样可以确保你作为用户在分页查询一个商品的，评论时，一般都是直接从一个库的一张表里执行分页查询语句就可以了

- **针对一个商品几十万评论的深分页问题**

- SQL

  ```mysql
  //只看xx商品的好评
  SELECT * FROM comments WHERE product_id ='xx' and is_good_comment='1' ORDER BY id desc LIMIT 100000,20
  ```

  最核心的索引就是一个，那就是index_product_id，会通过index_product_id索引，根据product_id ='xx'这个条件从表里先删选出来这个表里指定商品的评论数据。

- 问题分析

  这个index_product_id的索引数据里，并没有is_good_commet字段的值，所以此时只能很尴尬的进行回表了。也就是说，对这个商品的每一条评论，都要进行一次回表操作，回到聚簇索引里，根据id找到那条数据，取出来is_good_comment字段的值，接着对is_good_comment='1'条件做一个比对，筛选符合条件的数据。这个过程，因为有几十万次回表查询，还有十多万条数据的磁盘文件排序，所以这条SQL语句基本要跑个1秒~2秒。

- 解决方案(使用子表优化)

  在第三个案例里，就是根据category和sub_category组成的联合索引进行查找，所以不需要回表，这就节省下了大量回表操作的耗时，所以当时我们选择了这个方案。然后接着直接根据id临时磁盘文件排序后找到20条分页数据，再回表查询20次，找到20条商品的完整数据。因为不涉及到大量回表的问题，所以这么做基本是合适的，性能通常在1s以内。

  但这个案例里，就不是这么回事了，因为WHERE product_id ='xx' and is_good_comment='1'这两个条件，不是一个联合索引，所以必须会出现大量的回表操作，这个耗时是极高的。所以通常会采取如下方式改造分页查询语句：

```mysql
SELECT * from comments a, (SELECT id FROM comments WHERE product_id ='xx' and is_good_comment='1' ORDER BY id desc LIMIT 100000,20) b WHERE a.id=b.id
```

通常会先执行括号里的子查询，子查询反而会使用PRIMARY聚簇索引，按照聚簇索引的id值的倒序方向进行扫描，扫描过程中就把符合WHERE product_id ='xx' and is_good_comment='1'条件的数据给筛选出来

比如这里就筛选出了十万多条的数据，并不需要把符合条件的数据都找到，因为limit后跟的是100000,20，理论上，只要有100000+20条符合条件的数据，而且是按照id有序的，此时就可以执行根据limit 100000,20提取到5001页的这20条数据了。接着你会看到执行计划里会针对这个子查询的结果集，一个临时表，进行全表扫描，拿到20条数据，接着对20条数据遍历，每一条数据都按照id去聚簇索引里查找一下完整数据，就可以了。

所以针对我们的这个场景，反而是优化成这种方式来执行分页，他会更加合适一些，他只有一个扫描聚簇索引筛选符合你分页所有数据的成本，你的分页深度越深，扫描数据越多，分页深度越浅，那扫描数据就越少，然后再做一页20条数据的20次回表查询就可以了。

但是这里还是要给大家提醒一点，大家会发现，SQL调优实际上是没有银弹的，比如对于第三个案例来说，按顺序扫描聚簇索引方案可能会因为找不到数据导致亿级数据量的全表扫描，所以对第三个案例而言，必须得根据二级索引去查找。

但是对于我们这第四个案例而言，因为前提是做了分库分表，评论表单表数据一般在一百万左右，所以首先，他即使一个商品没有评论，有全表扫描，也绝对不会像扫描上亿数据表那么慢其次，如果你根据product_id的二级索引查找，反而可能出现几十万次回表查询，所以二级索引查找方式反而不适合，而按照聚簇索引顺序扫描的方式更加适合。

### 千万级数据删除导致的慢查询优化实践

- 案例背景

  有人删除了千万级的数据，结果导致了频繁的慢查询，

- 问题分析

  因为SQL本身完全不应该有慢查询，按说那种SQL语句，基本上都是直接根据索引查找出来的，性能应该是极高的。那么有没有可是MySQL生产服务器的问题呢？实际上个别特殊情况下，MySQL出现慢查询并不是SQL语句的问题，而是他自己生产服务器的负载太高了，导致SQL语句执行很慢。

  比如现在MySQL服务器的磁盘IO负载特别高，也就是每秒执行大量的高负载的随机IO，但是磁盘本身每秒能执行的随机IO是有限的。结果呢，就导致你正常的SQL语句去磁盘上执行的时候，如果要跑一些随机IO，你的磁盘太繁忙了，顾不上你了，导致你本来很快的一个SQL，要等很久才能执行完毕，这个时候就可能导致正常SQL语句也会变成慢查询！

  同理，除了磁盘之外，还有一个例子就是网络，也许网络负载很高，就可能会导致你一个SQL语句要发送到MySQL上去，光是等待获取一个跟MySQL的连接，都很难，要等很久，或者MySQL自己网络负载太高了，带宽打满，带宽打满了之后，你一个SQL也许执行很快，但是他查出来的数据返回给你，网络都送不出去，此时也会变成慢查询

  另外一个关键的点就是CPU负载，如果说CPU负载过高的话，也会导致CPU过于繁忙去执行别的任务了，没时间执行你这个SQL语句，此时也有可能会导致你的SQL语句出现问题的，所以这个大家也得注意。

  **所以说慢查询本身不一定是SQL导致的，如果你觉得SQL不应该慢查询，结果他那个时间段跑这个SQL就是慢，此时你应该排查一下当时MySQL服务器的负载，尤其看看磁盘、网络以及CPU的负载，是否正常**

- 解决方案

  如果你发现那个时间段MySQL生产服务器的磁盘、网络或者CPU负载特别高，那么可能是服务器负载导致的问题

  ```mysql
  举个例子，我们之前解决过一个典型的问题，就是当某个离线作业瞬间大批量把数据往MySQL里灌入的时候，他一瞬间服务器磁盘、网络以及CPU的负载会超高。此时你一个正常SQL执行下去，短时间内一定会慢查询的，针对类似的问题，优化手段更多的是控制你导致MySQL负载过高的那些行为，比如灌入大量数据，最好在凌晨低峰期灌入，别影响线上系统运行。
  ```

  如果MySQL服务器的磁盘、网络以及CPU负载，一切正常，SQL也没有问题，就要用MySQLprofifilling工具去细致的分析SQL语句的执行过程和耗时。